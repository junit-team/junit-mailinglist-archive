{
    "numMessagesInTopic": 24, 
    "nextInTime": 23476, 
    "senderId": "DnDevsKAIVuNKhMfTOJZjnifsYOQSbxGGKLPebqZci9fgIWAb92NsOfhRAl20VBy2Y-yUTvR2snAGXf_WLFnIAVNBNmEr1adHwmEbZXJjQSYwg", 
    "systemMessage": false, 
    "subject": "Re: [junit] Not knowing the tests in advance when providing a test runner", 
    "from": "Joakim Ohlrogge &lt;joakim.ohlrogge@...&gt;", 
    "authorName": "Joakim Ohlrogge", 
    "msgSnippet": "Jumi looks very interesting. It would be great with one API to run them all and in darkness bind them so to speak :) Basically talk to one API to get access", 
    "msgId": 23475, 
    "profile": "j0hlrogge", 
    "topicId": 23466, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 261856052, 
    "messageBody": "<div id=\"ygrps-yiv-2058205907\">Jumi looks very interesting. It would be great with &quot;one API to run them all<br/>\nand in darkness bind them&quot; so to speak :) Basically talk to one API to get<br/>\naccess to all the different test frameworks out there. I had an idea along<br/>\nthose lines that focused on the other end sort of. To &quot;just&quot; be a rosetta<br/>\nstone, but not be the smallest common denominator between all test<br/>\nframeworks but rather embrace their differences.<br/>\nOne of the big challenges was statuses and I think my thoughts were along<br/>\nthe lines of RDF where one could express that things that &quot;pending&quot; is a<br/>\nkind of &quot;ignored&quot; for reporting purposes but differs in that it is yet to be<br/>\nimplemented. Basically I approached things from the reporting side rather<br/>\nthan the running side since most test frameworks seem to not want to deal<br/>\nwith guis, ide integraton and such but focus on what a test looks like when<br/>\nit is written.<br/>\n<br/>\nWhen I read about Jumi I sort of hoped that Jumi could become this rosetta<br/>\nstone... but a more ambitious one.<br/>\n-----------------------------------------------------<br/>\nJoakim Ohlrogge<br/>\nAgical AB<br/>\nV�sterl�nggatan 79, 2 tr<br/>\n111 29 Stockholm, SWEDEN<br/>\n<br/>\nMobile: +46-708-754004<br/>\nBlog: johlrogge.wordpress.com<br/>\nTwitter: @johlrogge<br/>\nE-mail: <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:joakim.ohlrogge@...\">joakim.ohlrogge@...</a><br/>\n<br/>\n<br/>\n<blockquote><span title=\"qreply\"> On Wed, Jun 22, 2011 at 6:14 PM, Esko Luontola &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:esko.luontola@...\">esko.luontola@...</a>&gt;wrote:<br/>\n<br/>\n&gt; **<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; I had the same issue with Specsy and used the workaround of running the<br/>\n&gt; tests when the Runner&#39;s getDescription() or run() method is called the<br/>\n&gt; first time. [1] This causes the issue that for example IDEA&#39;s test<br/>\n&gt; runner cannot report the test progress in real time - the tests are<br/>\n&gt; executed before the progress bar is even started.<br/>\n&gt;<br/>\n&gt; As a long-term solution I&#39;m developing a new test runner [2] which<br/>\n&gt; solves this issue and has also a bunch of other improvements. The first<br/>\n&gt; release of that test runner should be some time later this summer.<br/>\n&gt;<br/>\n&gt; [1]<br/>\n&gt;<br/>\n&gt; <a rel=\"nofollow\" target=\"_blank\" href=\"https://github.com/orfjackal/specsy/blob/master/src/main/scala/net/orfjackal/specsy/junit/SpecsyJUnitRunner.scala\">https://github.com/orfjackal/specsy/blob/master/src/main/scala/net/orfjackal/specsy/junit/SpecsyJUnitRunner.scala</a><br/>\n&gt; [2] <a rel=\"nofollow\" target=\"_blank\" href=\"https://github.com/orfjackal/jumi\">https://github.com/orfjackal/jumi</a><br/>\n&gt;<br/>\n&gt; huntchrisalias wrote on 17.6.2011 15:43:<br/>\n&gt;<br/>\n&gt; &gt; Hi there,<br/>\n&gt; &gt;<br/>\n&gt; &gt; I&#39;m writing a custom test runner that is not easily able to determine<br/>\n&gt; &gt; how many tests will be executed in advance.<br/>\n&gt; &gt;<br/>\n&gt; &gt; The runner extends ParentRunner and its getChildren method is called<br/>\n&gt; &gt; prior to tests being executed via runChild. Each test is also described<br/>\n&gt; &gt; via describeChild.<br/>\n&gt; &gt;<br/>\n&gt; &gt; During runChild execution, if I create child descriptions of each child<br/>\n&gt; &gt; as each unforeseeable test occurs, then I get &quot;unrooted&quot; output.<br/>\n&gt; &gt;<br/>\n&gt; &gt; My actual use-case is that I have a test runner executing a series of<br/>\n&gt; &gt; tests within an html file. I would have to parse the html and its<br/>\n&gt; &gt; associated JavaScript to determine how many tests will be run. This<br/>\n&gt; &gt; would be tricky.<br/>\n&gt; &gt;<br/>\n&gt; &gt; Is there a recommended means of reporting the results of tests that are<br/>\n&gt; &gt; not determinable in advance?<br/>\n&gt; &gt;<br/>\n&gt; &gt; Kind regards,<br/>\n&gt; &gt; Christopher<br/>\n&gt;<br/>\n&gt; --<br/>\n&gt; Esko Luontola<br/>\n&gt; www.orfjackal.net<br/>\n&gt;<br/>\n&gt;  <br/>\n&gt;<br/>\n<br/>\n<br/>\n[Non-text portions of this message have been removed] </span></blockquote></div>", 
    "prevInTime": 23474, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1308777632", 
    "canDelete": false, 
    "nextInTopic": 23476, 
    "prevInTopic": 23474, 
    "headers": {
        "inReplyToHeader": "PDRFMDIxNEQ0LjIwNDA1MDRAZ21haWwuY29tPg==", 
        "messageIdInHeader": "PEJBTkxrVGltYWJtT0tSdkM2alBON0RiUFMyN2ZLemVWSlRnQG1haWwuZ21haWwuY29tPg==", 
        "referencesHeader": "PGl0Zmk1YSt1NTJjQGVHcm91cHMuY29tPiA8NEUwMjE0RDQuMjA0MDUwNEBnbWFpbC5jb20+"
    }
}