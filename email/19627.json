{
    "numMessagesInTopic": 48, 
    "nextInTime": 19628, 
    "senderId": "JGWyNHtrU9whABxi4VQNGU4m2hDUdExoYLTj0k6kj3HP_UXGffMuT0tETMuL4FdR4P480ahC8DCYbVzfVlzW0TYq0wCWsi95s6ozc57nWOsjYNl0pXPOACVNhAUg64kMDLPFy28", 
    "systemMessage": false, 
    "subject": "Re: [junit] Re: Test Grouping/Partitioning", 
    "from": "&quot;=?UTF-8?Q?C=C3=A9dric_Beust_=E2=99=94_?=&quot; &lt;cbeust@...&gt;", 
    "authorName": "Cédric Beust ♔", 
    "msgSnippet": "Hi Kent, Here are a few other classifications I ve seen TestNG users use these past years: - Test type:  unit, functional, integration, system, acceptance, ", 
    "msgId": 19627, 
    "profile": "cbeust", 
    "topicId": 19521, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 199443513, 
    "messageBody": "<div id=\"ygrps-yiv-1288583861\">Hi Kent,<br/>\n<br/>\nHere are a few other classifications I&#39;ve seen TestNG users use these past<br/>\nyears:<br/>\n<br/>\n   - Test type:  unit, functional, integration, system, acceptance,<br/>\n   performance.<br/>\n   - Test size:  small, medium, large.<br/>\n   - Functional description:  web, gui, html, jsp, servlet, database,<br/>\n   back-end.<br/>\n   - Speed of the test:  slow, fast.<br/>\n   - Procedural:  check-in, smoke-test, milestone, release.<br/>\n   - Platform:  os.win32, os.linux, os.mac-os<br/>\n   - Hardware:  single-core, multi-core, dual-cpu, memory.1gig, memory.<br/>\n   - Runtime schedule:  week-days, weekends, nightly, monthly<br/>\n<br/>\nAbout your Assurance/CPU point:  in my experience, CPU very quickly stops<br/>\nbeing the bottleneck for functional tests.<br/>\n<br/>\nNetwork bandwidth, I/O throughput, environment setup and test data<br/>\ninitialization or uninitialization are what takes most of the time of<br/>\nlengthy tests as your application grows.  And as I said before, test runs<br/>\nthat take hours if not sometimes entire nights to run are pretty common in<br/>\nenterprise software.<br/>\n<br/>\n-- <br/>\nCedric<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://testng.org\">http://testng.org</a><br/>\n<br/>\n<br/>\n<br/>\n<blockquote><span title=\"qreply\"> On 7/26/07, Kent Beck &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:kentb@...\">kentb@...</a>&gt; wrote:<br/>\n&gt;<br/>\n&gt;   All,<br/>\n&gt;<br/>\n&gt; It seems clear to me that some sort of test classification scheme is a<br/>\n&gt; reasonable thing to add to JUnit. However, rather than simply copy one of<br/>\n&gt; the models out there we&#39;re going to go back to first principles and try to<br/>\n&gt; derive a model for classification that is concise, useful, flexible, and,<br/>\n&gt; above all, easy to use.<br/>\n&gt;<br/>\n&gt; I&#39;ve heard two purposes for classification:<br/>\n&gt; * Performance<br/>\n&gt; * Assumptions<br/>\n&gt;<br/>\n&gt; Performance<br/>\n&gt;<br/>\n&gt; If you have tests that run for longer than your attention span (my limits<br/>\n&gt; are 1 second for the inner loop of programming and 10 minutes for<br/>\n&gt; integration), running a subset of the tests can give you some assurance<br/>\n&gt; that<br/>\n&gt; the software is working. Classification is one way to reduce test run<br/>\n&gt; time--just this one test, all tests in this class, all tests in this<br/>\n&gt; package, all tests labeled &quot;quick&quot;, etc.<br/>\n&gt;<br/>\n&gt; There are other ways of reducing test run time. For example, you could<br/>\n&gt; have<br/>\n&gt; a runner that runs 1 second worth of the tests that have failed most<br/>\n&gt; recently or a runner that runs half a second of recently failed tests plus<br/>\n&gt; half a second of randomly selected tests.<br/>\n&gt;<br/>\n&gt; In the end I think the systemic solution to test run times is to improve<br/>\n&gt; design and testing techniques to dramatically increase the assurance/CPU<br/>\n&gt; cycle ratio.<br/>\n&gt;<br/>\n&gt; I remember a friend&#39;s story of an early project that used tests<br/>\n&gt; extensively.<br/>\n&gt; After three years they had a carefully tuned suite that took ten minutes<br/>\n&gt; to<br/>\n&gt; run. When the test runtime increased beyond ten minutes, they would work<br/>\n&gt; on<br/>\n&gt; the design of the system and/or the design of the tests to improve the<br/>\n&gt; assurance/CPU cycle ratio and get the runtime back under ten minutes. Then<br/>\n&gt; most of the original team left.<br/>\n&gt;<br/>\n&gt; A few years later my friend was shown the system. The programmer proudly<br/>\n&gt; explained that the test suites now took 24 hours to run, even though the<br/>\n&gt; system had grown little in functionality. They had stopped paying<br/>\n&gt; attention<br/>\n&gt; to designing for testability. Every time they added a new axis of<br/>\n&gt; variability they blindly ran the cross product of the existing tests with<br/>\n&gt; all the alternatives for the new axis. Yes they had more tests, but A/C<br/>\n&gt; had<br/>\n&gt; dropped by several orders of magnitude.<br/>\n&gt;<br/>\n&gt; In short, I see using classification to reduce test runtime as a bandage<br/>\n&gt; masking the real problem which is low A/C. Using classification to reduce<br/>\n&gt; test runtime really is a hack and I hope people will continue working to<br/>\n&gt; improve design for testability. We will still provide some classification<br/>\n&gt; mechanism, but that doesn&#39;t make it not a hack.<br/>\n&gt;<br/>\n&gt; Assumptions<br/>\n&gt;<br/>\n&gt; The second reason I&#39;ve heard for classification is to avoid a slew of<br/>\n&gt; misleadingly failing tests. If my development machine doesn&#39;t have access<br/>\n&gt; to<br/>\n&gt; the database, then if I run the database tests I&#39;ll get a bunch of<br/>\n&gt; failures<br/>\n&gt; even though the system is really working (or, to be more precise, I don&#39;t<br/>\n&gt; have any information about whether the system is really working or not).<br/>\n&gt;<br/>\n&gt; Classification is one way to express assumptions. When I say &quot;@Test(groups<br/>\n&gt; =<br/>\n&gt; {&quot;database&quot;})&quot; I have declared something about this test. However, this<br/>\n&gt; expression seems limited and error-prone to me. I&#39;d prefer to have the<br/>\n&gt; power<br/>\n&gt; of a programming language to express my assumptions.<br/>\n&gt;<br/>\n&gt; In the JUnit 4.4 you can use assumeThat() to express assumptions. For<br/>\n&gt; example, you can say:<br/>\n&gt;<br/>\n&gt; public class DatabaseTest {<br/>\n&gt; @BeforeClass public static void isDatabaseAccessible() {<br/>\n&gt; User result= Database.login(&quot;kent&quot;);<br/>\n&gt; assumeThat(not(isError(result));<br/>\n&gt; }<br/>\n&gt; ...<br/>\n&gt; }<br/>\n&gt;<br/>\n&gt; This is a bit of a workaround because runner don&#39;t yet handle failed<br/>\n&gt; assumptions as anything other than successful tests, but it gives you a<br/>\n&gt; richer language to express assumptions than a textual classification<br/>\n&gt; scheme.<br/>\n&gt;<br/>\n&gt; The Point<br/>\n&gt;<br/>\n&gt; So now the point of this long post. Are there other uses of classification<br/>\n&gt; that I&#39;ve missed? Is the above way of expressing assumptions (or something<br/>\n&gt; derived from it like an explicit @Assumption) sufficient?<br/>\n&gt;<br/>\n&gt; Regards,<br/>\n&gt;<br/>\n&gt; Kent Beck<br/>\n&gt; Three Rivers Institute<br/>\n&gt;<br/>\n&gt; [Non-text portions of this message have been removed]<br/>\n&gt;<br/>\n&gt;  <br/>\n&gt;<br/>\n<br/>\n<br/>\n<br/>\n-- <br/>\nCédric<br/>\n<br/>\n<br/>\n[Non-text portions of this message have been removed] </span></blockquote></div>", 
    "prevInTime": 19626, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1185490560", 
    "canDelete": false, 
    "nextInTopic": 19631, 
    "prevInTopic": 19626, 
    "headers": {
        "inReplyToHeader": "PDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPg==", 
        "messageIdInHeader": "PGI4NmI2YTljMDcwNzI2MTU1NmozYTYyMTA0OGoyNzQxNTNiMTM4YjIxNjc4QG1haWwuZ21haWwuY29tPg==", 
        "referencesHeader": "PDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPg=="
    }
}