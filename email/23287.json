{
    "numMessagesInTopic": 5, 
    "nextInTime": 23288, 
    "senderId": "9v0c5k8mSE345GmAGzwGLugoL-DowIXBa9gy2x_Eu0OGoBvMxe1Mmnd_b-3bdW7YyJHahLS7V-vF6urgdyu9YGSh9KR9VR_eZb_gNgE52tSKEmWfpQvJ78inVqU", 
    "systemMessage": true, 
    "subject": "Automatic parallel- (aka regression-) testing in JUnit", 
    "from": "&quot;julianbutnotassange&quot; &lt;julianbutnotassange@...&gt;", 
    "authorName": "julianbutnotassange", 
    "msgSnippet": "Hi there, I hope this is the right group to ask. Terminology in the literature is a bit all over the place so please be patient and let me try to clarify. (I m", 
    "msgId": 23287, 
    "profile": "julianbutnotassange", 
    "topicId": 23287, 
    "spamInfo": {
        "reason": "6", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 476316842, 
    "messageBody": "<div id=\"ygrps-yiv-3895487\">Hi there,<br/>\n<br/>\nI hope this is the right group to ask.<br/>\nTerminology in the literature is a bit all over the place so please be patient and let me try to clarify. (I&#39;m also coming from a different language.)<br/>\n<br/>\nWhat I&#39;m about to describe could potentially be done continuously, but it is drifting away from Unit testing into Integration/Story testing that I would do e.g. every day, or every week.<br/>\nSay I have a method that outputs an object of type MyClass.<br/>\nI have a version of this method in production, and I know it outputs an acceptable object.<br/>\nWhen I have a release candidate, I would like to calculate the object with the new code and compare against the object calculated with the production code, ideally according to a user-defined tolerance for floats.<br/>\n<br/>\nLet&#39;s say I have an integration test which simply calculates the value and performs some intrinsic tests on the output.<br/>\nI would imagine that with some generic, recursive reflection and persistence it would be possible to extend JUnit so that I can just add one line to my integration test, so that<br/>\n<br/>\n1. if the test is run in &quot;integration mode&quot;, that line is ignored<br/>\n2. if the test is run in &quot;regression_base mode&quot; against production, it persists the output value (expected) somewhere<br/>\n3. if the test is run in &quot;regression_compare&quot; mode, it loads back the expected and automatically and generically compares it against the actual that I already have in memory at that point<br/>\n<br/>\nand this would work for an arbitrary object of an arbitrary type, without requiring the test writer to write anything else. Something like this<br/>\n<br/>\npublic class MyClassTest extends RegressionTest {<br/>\n  @Test<br/>\n  public void myIntegrationTest() {<br/>\n    MyClass myOutput = Whatever.StoryTest();<br/>\n<br/>\n    // This is a standard assertion, part of the story test.<br/>\n    // It always gets executed.<br/>\n    assertTrue(&quot;A reasonable amount&quot;, output.GetAmount() &lt; 50);<br/>\n<br/>\n    // This does something different depending on what &quot;mode&quot; the test is running in.<br/>\n    // The last argument is the tolerance for float comparisons<br/>\n    assertNoRegression(&quot;Regression-testing myOutput&quot;, myObject, 10e-2);<br/>\n  }<br/>\n}<br/>\n<br/>\nDo you think this can be achieved in Java? Perhaps something has already been done?<br/>\n<br/>\nThank you</div>", 
    "prevInTime": 23286, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1298438055", 
    "canDelete": false, 
    "nextInTopic": 23288, 
    "prevInTopic": 0, 
    "headers": {
        "messageIdInHeader": "PGlrMjUzNytzamg5QGVHcm91cHMuY29tPg=="
    }
}