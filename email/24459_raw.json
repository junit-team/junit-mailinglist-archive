{
    "numMessagesInTopic": 13, 
    "nextInTime": 24460, 
    "senderId": "eBrQGL92VOE9xTlRhjn0zhvIb369i_xXjk_oMROgDnmElD9k4v603mOG4RIQJi6yWHHC9mOPqc1Sg4__TSQuW23kQ2_5844IYvaaVe96EK4UQEMESDaRdjY", 
    "systemMessage": false, 
    "subject": "Re: [junit] RE: Tool to create assertions from a running Java application", 
    "from": "Stephen Connolly &lt;stephen.alan.connolly@...&gt;", 
    "authorName": "Stephen Connolly", 
    "msgSnippet": "There is a siren that I call 100% code coverage. You hear the siren call most strongly from practitioners in those languages that have dynamic/weak typing, a", 
    "msgId": 24459, 
    "rawEmail": "Return-Path: &lt;stephen.alan.connolly@...&gt;\r\nReceived: (qmail 84627 invoked by uid 7800); 3 Feb 2014 14:02:05 -0000\r\nX-Sender: stephen.alan.connolly@...\r\nX-Apparently-To: junit@yahoogroups.com\r\nX-Received: (qmail 60685 invoked by uid 102); 3 Feb 2014 12:58:11 -0000\r\nX-Received: from unknown (HELO mtaq6.grp.bf1.yahoo.com) (10.193.84.37)\n  by m3.grp.bf1.yahoo.com with SMTP; 3 Feb 2014 12:58:11 -0000\r\nX-Received: (qmail 6203 invoked from network); 3 Feb 2014 12:58:11 -0000\r\nX-Received: from unknown (HELO mail-pd0-f174.google.com) (209.85.192.174)\n  by mtaq6.grp.bf1.yahoo.com with SMTP; 3 Feb 2014 12:58:11 -0000\r\nX-Received: by mail-pd0-f174.google.com with SMTP id z10so6800924pdj.19\n        for &lt;junit@yahoogroups.com&gt;; Mon, 03 Feb 2014 04:58:11 -0800 (PST)\r\nMIME-Version: 1.0\r\nX-Received: by 10.69.20.11 with SMTP id gy11mr37233384pbd.64.1391432278215;\n Mon, 03 Feb 2014 04:57:58 -0800 (PST)\r\nX-Received: by 10.68.147.102 with HTTP; Mon, 3 Feb 2014 04:57:58 -0800 (PST)\r\nIn-Reply-To: &lt;lcnh7c+1gkmjj4@...&gt;\r\nReferences: &lt;lcitqg+1ht5u3i@...&gt;\n\t&lt;52ED55F5.8030602@...&gt;\n\t&lt;lcnh7c+1gkmjj4@...&gt;\r\nDate: Mon, 3 Feb 2014 12:57:58 +0000\r\nMessage-ID: &lt;CA+nPnMzH4QymYsyzabtogsDOFOdbjRL-ruJBsaSzdKwg_x3n9Q@...&gt;\r\nTo: &quot;junit@yahoogroups.com&quot; &lt;junit@yahoogroups.com&gt;\r\nContent-Type: multipart/alternative; boundary=001a11367344ac12fb04f1801202\r\nX-eGroups-Msg-Info: 1:12:0:0:0\r\nFrom: Stephen Connolly &lt;stephen.alan.connolly@...&gt;\r\nSubject: Re: [junit] RE: Tool to create assertions from a running Java application\r\nX-Yahoo-Group-Post: member; u=458231986; y=jcGU0odtS-Jxg_gYwe5NOMmre2_soljiIAas3RtqAxj9_NkpDJ3PygdZ5WNmHA\r\nX-Yahoo-Profile: stephenalanconnolly\r\nX-eGroups-Approved-By: dsaff &lt;david@...&gt; via email; 3 Feb 2014 14:02:05 -0000\r\n\r\n\r\n--001a11367344ac12fb04f1801202\r\nContent-Type: text/plain; charset=ISO-8859-1\r\n\r\nThere is a siren that I call 100% code coverage.\n\nYou hear the siren call most strongly from practitioners in those languages\nthat have dynamic/weak typing, a global variable scope and are interpreted.\n\nWhen you are dealing with a static/semi-strongly typed language such as\nJava, which is compiled and does not have a real global variable scope\n(closest thing is System.getProperties() which can only hold String\ninstances), the compiler itself ensures that 100% of lines are subject to\nsome tests (i.e. namely is it syntactically correct and does it match the\ntyping rules)... on top of which you can add more &quot;tests&quot; using tooling\nsuch as findbugs, PMD and checkstyle (assuming you use a zero-failures\npolicy)\n\nIs that enough tests for Java code... hell no... but you have 100% code\ncoverage... the code coverage you measure with tooling such as\ncobertura/clover/emma/jacoco is the additional coverage you get from the\nadditional tests you have written.\n\nWhen a dynamic typing interpretive language person asks: &quot;are you\ncomfortable releasing your 10,000 lines of code with 1% of those lines not\ntested? that&#39;s 100 lines without tests?&quot; they are asking because there\ncould be a syntax or type error in one of those 100 lines that causes their\ncode to blow up. I would not be comfortable with such.\n\nWith a compiled static typing language, however, the answer is &quot;yes we do\nhave tests... the compiler gives us tests... they may not be our best\ntests... but we have tests... shall we take a look at all your tests and\nsee how good they are in order to get to 100% coverage?&quot;\n\nMy point is this:\n\nWith a language like Java, 100% code coverage is not the goal. Quality\ntests is the goal.\n\nIt is easy to &quot;generate&quot; tests from code... the kind of tests you end up\nwith will verify that the code behaves the same as before... so when you\nchange *anything meaningful* some tests will fail... only now you don&#39;t\nknow why the tests are failing... is it because you changed the code to\nmatch the new requirement... or is it because you broke something else in\nthe process?\n\nQuality tests are about meaningful test names and small test case size with\nat most 1-2 asserts per test case.\n\nThe test name should tell you what is being tested and why. The 1-2 asserts\n(should really be just 1) should validate the actual outcome.\n\n@Test\nvoid lookUpWidgetById_nullId() {\n  assertThat(instance.lookup(null), is(nullValue());\n}\n\n@Test\nvoid lookUpWidgetById_standardWidget() {\n  assertThat(instance.lookup(STANDARD_WIDGET_ID),\nis(hasProperty(&quot;id&quot;,STANDARD_WIDGET_ID)));\n}\n\nis a better quality of tests than\n\n@Test\nvoid lookUpWidgetById() {\n  assertThat(instance.lookup(null), is(nullValue());\n  assertThat(instance.lookup(STANDARD_WIDGET_ID),\nis(hasProperty(&quot;id&quot;,STANDARD_WIDGET_ID)));\n}\n\nSimilarly\n\n@Test\nvoid manchuify_hasFrongles() {\n  Foo instance = new Foo();\n  assertThat(instance.getFrongleCount(), is(0));\n  instance.manchuify();\n  assertThat(instance.getFrongleCount(), is(greaterThan(0)));\n}\n\n@Test\nvoid manchuify_isRed() {\n  Foo instance = new Foo();\n  assertThat(instance.getColor(), not(is(Color.RED)));\n  instance.manchuify();\n  assertThat(instance.getColor(), is(Color.RED));\n}\n\nis better quality than\n\n@Test\nvoid manchuify() {\n  Foo instance = new Foo();\n  assertThat(instance.getFrongleCount(), is(0));\n  assertThat(instance.getColor(), not(is(Color.RED)));\n  instance.manchuify();\n  assertThat(instance.getFrongleCount(), is(greaterThan(0)));\n  assertThat(instance.getColor(), is(Color.RED));\n}\n\nbecause by splitting out the tests we know that these are individual\nrequirements... in addition we also know the scope of the problem... if\nsomething happens the Foo.manchuify() method that it no longer makes the\nFoo instances red, in both cases we get two failing tests... but the better\nquality test tells us exactly what is wrong.\n\nWith automated test generation based off either the compiled code or the\nrunning system, the tool cannot tell you why things are the way they are,\nso hence the tool cannot give the tests good names, and cannot\ndifferentiate the related elements... the frongle count being non zero and\nthe colour being red are strongly correlated, so how can the system know\nthat these are a side-effect of the original spec and that the new spec\nallows for non-red Foo instances after manchuification?\n\nIf you are a smart developer, you will understand all of the above... and\nyou will be saying... this is just a tool... I am the person who will step\nin and create the context... I just want some automation to take out the\ngrunt work...\n\nWell that is fine as long as you don&#39;t ever face a manager who fears the\neven 1 untested line of code in their source release, or who receives an\nedict from the on-high CTO (who was raised on dynamic interpreted\nlanguages) and now has to get to 100% coverage... sees the tooling and sees\nit as a route to 100% coverage...\n\nThe end effect of that tooling is that the entire code base is frozen in\nplace, as any change results in a complete cascade of test failures... and\nyou run off analysing each and every one just to determine whether the\nchange is the intended effect and the test needs updating, or whether the\ntest is right and you broke something you shouldn&#39;t have.\n\nIt&#39;s not about the % coverage... it&#39;s about the quality of your test\ncases... automated tooling will not produce quality test cases (unless they\nare processing an independently derived specification... in which case who\ntests the specification to be correct... Quis custodiet ipsos custodes?)\n\n-Stephen\n\n\nOn 3 February 2014 07:41, &lt;mirko.sertic@...&gt; wrote:\n\n&gt;\n&gt;\n&gt; Hi there\n&gt;\n&gt; Yes, i totally agree with you: the TDD way is a much more useful way to\n&gt; create software. From my point of view this is the way to go for a\n&gt; greenfield project.\n&gt;\n&gt; However, while working with legacy code this is not always possible. The\n&gt; described tool is a simple helper class to create a good test coverage for\n&gt; existing codebases before changing something, so basically it is a TDD\n&gt; helper. Nothing more. Of course it is up to the designer to check what is\n&gt; tested and create a good test strategy. For our current project, this\n&gt; simple helper saved us a lot of time, so i want to share it with the\n&gt; community.\n&gt;\n&gt; Regards\n&gt; Mirko\n&gt;\n&gt; \n&gt;\n\r\n--001a11367344ac12fb04f1801202\r\nContent-Type: text/html; charset=ISO-8859-1\r\nContent-Transfer-Encoding: quoted-printable\r\n\r\n&lt;div dir=3D&quot;ltr&quot;&gt;There is a siren that I call 100% code coverage.&lt;div&gt;&lt;br&gt;&lt;=\r\n/div&gt;&lt;div&gt;You hear the siren call most strongly from practitioners in those=\r\n languages that have dynamic/weak typing, a global variable scope and are i=\r\nnterpreted.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;When you are dealing with a static/se=\r\nmi-strongly typed language such as Java, which is compiled and does not hav=\r\ne a real global variable scope (closest thing is System.getProperties() whi=\r\nch can only hold String instances), the compiler itself ensures that 100% o=\r\nf lines are subject to some tests (i.e. namely is it syntactically correct =\r\nand does it match the typing rules)... on top of which you can add more &qu=\r\not;tests&quot; using tooling such as findbugs, PMD and checkstyle (assuming=\r\n you use a zero-failures policy)&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Is that enough t=\r\nests for Java code... hell no... but you have 100% code coverage... the cod=\r\ne coverage you measure with tooling such as cobertura/clover/emma/jacoco is=\r\n the additional coverage you get from the additional tests you have written=\r\n.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;When a dynamic typing interpretive language per=\r\nson asks: &quot;are you comfortable releasing your 10,000 lines of code wit=\r\nh 1% of those lines not tested? that&#39;s 100 lines without tests?&quot; t=\r\nhey are asking because there could be a syntax or type error in one of thos=\r\ne 100 lines that causes their code to blow up. I would not be comfortable w=\r\nith such.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;With a compiled static typing language,=\r\n however, the answer is &quot;yes we do have tests... the compiler gives us=\r\n tests... they may not be our best tests... but we have tests... shall we t=\r\nake a look at all your tests and see how good they are in order to get to 1=\r\n00% coverage?&quot;&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;My point is this:&lt;/div&gt;&lt;div&gt;&lt;=\r\nbr&gt;&lt;/div&gt;&lt;div&gt;With a language like Java, 100% code coverage is not the goal=\r\n. Quality tests is the goal.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It is easy to &quot;g=\r\nenerate&quot; tests from code... the kind of tests you end up with will ver=\r\nify that the code behaves the same as before... so when you change *anythin=\r\ng meaningful* some tests will fail... only now you don&#39;t know why the t=\r\nests are failing... is it because you changed the code to match the new req=\r\nuirement... or is it because you broke something else in the process?&lt;/div&gt;=\r\n\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Quality tests are about meaningful test names and smal=\r\nl test case size with at most 1-2 asserts per test case.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/di=\r\nv&gt;&lt;div&gt;The test name should tell you what is being tested and why. The 1-2 =\r\nasserts (should really be just 1) should validate the actual outcome.&lt;/div&gt;=\r\n\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;@Test&lt;/div&gt;&lt;div&gt;void lookUpWidgetById_nullId() {&lt;/div&gt;=\r\n&lt;div&gt;=A0 assertThat(instance.lookup(null), is(nullValue());&lt;/div&gt;&lt;div&gt;}&lt;/di=\r\nv&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;@Test&lt;/div&gt;&lt;div&gt;void lookUpWidgetById_standardWidget(=\r\n) {&lt;/div&gt;\n&lt;div&gt;=A0 assertThat(instance.lookup(STANDARD_WIDGET_ID), is(hasPr=\r\noperty(&quot;id&quot;,STANDARD_WIDGET_ID)));&lt;/div&gt;&lt;div&gt;}&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/di=\r\nv&gt;&lt;div&gt;is a better quality of tests than=A0&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;@=\r\nTest&lt;/div&gt;\n&lt;div&gt;void lookUpWidgetById() {&lt;/div&gt;&lt;div&gt;=A0 assertThat(instance=\r\n.lookup(null), is(nullValue());&lt;/div&gt;&lt;div&gt;=A0 assertThat(instance.lookup(ST=\r\nANDARD_WIDGET_ID), is(hasProperty(&quot;id&quot;,STANDARD_WIDGET_ID)));&lt;br&gt;=\r\n&lt;/div&gt;&lt;div&gt;\n}&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Similarly&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;=\r\n&lt;div&gt;@Test&lt;/div&gt;&lt;div&gt;void manchuify_hasFrongles() {&lt;/div&gt;&lt;div&gt;=A0 Foo insta=\r\nnce =3D new Foo();&lt;/div&gt;&lt;div&gt;=A0 assertThat(instance.getFrongleCount(), is(=\r\n0));&lt;/div&gt;&lt;div&gt;\n=A0 instance.manchuify();&lt;/div&gt;&lt;div&gt;=A0 assertThat(instance=\r\n.getFrongleCount(), is(greaterThan(0)));&lt;/div&gt;&lt;div&gt;}&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;d=\r\niv&gt;&lt;div&gt;@Test&lt;/div&gt;&lt;div&gt;void manchuify_isRed() {&lt;/div&gt;&lt;div&gt;=A0 Foo instance=\r\n =3D new Foo();&lt;/div&gt;\n&lt;div&gt;=A0 assertThat(instance.getColor(), not(is(Color=\r\n.RED)));&lt;/div&gt;&lt;div&gt;=A0 instance.manchuify();&lt;/div&gt;&lt;div&gt;=A0 assertThat(insta=\r\nnce.getColor(), is(Color.RED));&lt;/div&gt;&lt;div&gt;}&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;=\r\nis better quality than&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;@Test&lt;/div&gt;&lt;div&gt;void =\r\nmanchuify() {&lt;/div&gt;&lt;div&gt;=A0 Foo instance =3D new Foo();&lt;/div&gt;&lt;div&gt;=A0 asser=\r\ntThat(instance.getFrongleCount(), is(0));&lt;/div&gt;&lt;div&gt;=A0 assertThat(instance=\r\n.getColor(), not(is(Color.RED)));&lt;br&gt;\n&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;=A0 instance.ma=\r\nnchuify();&lt;/div&gt;&lt;div&gt;=A0 assertThat(instance.getFrongleCount(), is(greaterT=\r\nhan(0)));&lt;/div&gt;&lt;div&gt;=A0 assertThat(instance.getColor(), is(Color.RED));&lt;br&gt;=\r\n&lt;/div&gt;&lt;div&gt;&lt;div&gt;}&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;\n&lt;br&gt;&lt;/div&gt;&lt;div&gt;because by splittin=\r\ng out the tests we know that these are individual requirements... in additi=\r\non we also know the scope of the problem... if something happens the Foo.ma=\r\nnchuify() method that it no longer makes the Foo instances red, in both cas=\r\nes we get two failing tests... but the better quality test tells us exactly=\r\n what is wrong.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;With automated test generation ba=\r\nsed off either the compiled code or the running system, the tool cannot tel=\r\nl you why things are the way they are, so hence the tool cannot give the te=\r\nsts good names, and cannot differentiate the related elements... the frongl=\r\ne count being non zero and the colour being red are strongly correlated, so=\r\n how can the system know that these are a side-effect of the original spec =\r\nand that the new spec allows for non-red Foo instances after manchuificatio=\r\nn?&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;If you are a smart developer, you will underst=\r\nand all of the above... and you will be saying... this is just a tool... I =\r\nam the person who will step in and create the context... I just want some a=\r\nutomation to take out the grunt work...&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Well that=\r\n is fine as long as you don&#39;t ever face a manager who fears the even 1 =\r\nuntested line of code in their source release, or who receives an edict fro=\r\nm the on-high CTO (who was raised on dynamic interpreted languages) and now=\r\n has to get to 100% coverage... sees the tooling and sees it as a route to =\r\n100% coverage...&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The end effect of that tooling i=\r\ns that the entire code base is frozen in place, as any change results in a =\r\ncomplete cascade of test failures... and you run off analysing each and eve=\r\nry one just to determine whether the change is the intended effect and the =\r\ntest needs updating, or whether the test is right and you broke something y=\r\nou shouldn&#39;t have.&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;It&#39;s not about the % c=\r\noverage... it&#39;s about the quality of your test cases... automated tooli=\r\nng will not produce quality test cases (unless they are processing an indep=\r\nendently derived specification... in which case who tests the specification=\r\n to be correct...=A0Quis custodiet ipsos custodes?)&lt;/div&gt;\n&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;d=\r\niv&gt;-Stephen&lt;/div&gt;&lt;/div&gt;&lt;div class=3D&quot;gmail_extra&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;div class=3D&quot;gma=\r\nil_quote&quot;&gt;On 3 February 2014 07:41,  &lt;span dir=3D&quot;ltr&quot;&gt;&lt;&lt;a href=3D&quot;mailt=\r\no:mirko.sertic@...&quot; target=3D&quot;_blank&quot;&gt;mirko.sertic@...&lt;/a&gt;&gt;&lt;/span&gt;=\r\n wrote:&lt;br&gt;\n&lt;blockquote class=3D&quot;gmail_quote&quot; style=3D&quot;margin:0 0 0 .8ex;bo=\r\nrder-left:1px #ccc solid;padding-left:1ex&quot;&gt;\n\n\n\n\n\n\n        \n\n\n\n\n&lt;div&gt;\n\n\n\n\n\n&lt;=\r\nbr&gt;&lt;br&gt;\n\n\n\n\nHi there&lt;br&gt;&lt;br&gt;Yes, i totally agree with you: the TDD way is a=\r\n much more useful way to create software. From my point of view this is the=\r\n way to go for a greenfield project.&lt;br&gt;&lt;br&gt;However, while working with leg=\r\nacy code this is not always possible. The described tool is a simple helper=\r\n class to create a good test coverage for existing codebases before changin=\r\ng something, so basically it is a TDD helper. Nothing more. Of course it is=\r\n up to the designer to check what is tested and create a good test strategy=\r\n. For our current project, this simple helper saved us a lot of time, so i =\r\nwant to share it with the community.&lt;br&gt;\n&lt;br&gt;Regards&lt;br&gt;Mirko\n\n\n\n\n\n&lt;br&gt;\n\n\n&lt;=\r\nbr&gt;\n\n\n\n\n&lt;div width=3D&quot;1&quot; style=3D&quot;color:white;clear:both&quot;&gt;&lt;/div&gt;\n&lt;/div&gt;\n\n\n&lt;=\r\n/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;\n\r\n--001a11367344ac12fb04f1801202--\r\n\n", 
    "profile": "stephenalanconnolly", 
    "topicId": 24453, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 458231986, 
    "prevInTime": 24458, 
    "contentTrasformed": false, 
    "postDate": "1391432278", 
    "canDelete": false, 
    "nextInTopic": 24460, 
    "prevInTopic": 24458, 
    "headers": {
        "inReplyToHeader": "PGxjbmg3YysxZ2ttamo0QFlhaG9vR3JvdXBzLmNvbT4=", 
        "messageIdInHeader": "PENBK25Qbk16SDRReW1Zc3l6YWJ0b2dzRE9GT2RialJMLXJ1SkJzYVN6ZEt3Z194M245UUBtYWlsLmdtYWlsLmNvbT4=", 
        "referencesHeader": "PGxjaXRxZysxaHQ1dTNpQFlhaG9vR3JvdXBzLmNvbT4JPDUyRUQ1NUY1LjgwMzA2MDJAZ21haWwuY29tPgk8bGNuaDdjKzFna21qajRAWWFob29Hcm91cHMuY29tPg=="
    }
}