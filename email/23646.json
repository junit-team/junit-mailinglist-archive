{
    "numMessagesInTopic": 13, 
    "nextInTime": 23647, 
    "senderId": "78KX0uwZgJshUmt-1tACn-JushP0Z3bgJ7gssrDP7FOlFAdSc_9n1S7VQ2OqLwa5Se7IluwYOnBsHvpoFTR0QzeJWTM", 
    "systemMessage": true, 
    "subject": "Re: [junit] Feature request: @Assumes", 
    "from": "Dale Emery &lt;dale@...&gt;", 
    "authorName": "Dale Emery", 
    "msgSnippet": "Hi Stephen and all, ... More like TestNG s dependsOnMethods feature. I understand your desire for this. I also understand the JUnit guys reluctance to", 
    "msgId": 23646, 
    "profile": "dhemery@ymail.com", 
    "topicId": 23636, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 5352550, 
    "messageBody": "<div id=\"ygrps-yiv-919624633\">Hi Stephen and all,<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; Nope not a mock at all.<br/>\n&gt; <br/>\n </span></blockquote>More like TestNG&#39;s &quot;dependsOnMethods&quot; feature.<br/>\n<br/>\nI understand your desire for this. I also understand the JUnit guys&#39; reluctance to implement it. My intermediate-ish experience with TestNG leaves me with the conclusion that inter-test dependencies lead to madness. To be fair, I had already concluded that before working with clients who insisted on specifying inter-test dependencies.<br/>\n<br/>\nMy first half-baked thought is to use a Rule to prevent running methods that depend on another method that has already failed. But that would work only if the tests were run in the appropriate order.<br/>\n<br/>\nSo my next half-baked thought is to write a custom Runner that builds the dependency graph and sequences the tests accordingly. Then either the runner or a rule could decide whether to run a test. I&#39;m confident that a runner could do what you want, but that requires delving into the arcane bits of JUnit.<br/>\n<br/>\nA final half-baked thought: What if you ran all the tests, then used the dependency graph only to mark the results somehow, so as to highlight the tests on which others depend. If you see a swarm of failures, and the display indicates that some common prerequisite test also failed, that would aid your investigation.<br/>\n<br/>\nI&#39;ve seen situations where some prerequisite test fails, but some of the dependent tests pass. Sometimes the prerequisite test is lying to me (and I need to fix that). Sometimes the dependency is over-specified--the dependent test doesn&#39;t depend on everything that the prerequisite test tests (which means I need to refactor the prerequisite test and the dependency specifications). Sometimes it means that the prerequisite test fails intermittently (which means I need to track down the uncontrolled factors that affect the test).<br/>\n<br/>\nSkipping the dependent tests hides that information. Running them and marking them would highlight that<br/>\n<br/>\nDale<br/>\n<br/>\n--<br/>\nDale Emery<br/>\nConsultant to software teams and leaders<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://dhemery.com\">http://dhemery.com</a><br/>\n<br/>\n<br/>\n<br/>\n[Non-text portions of this message have been removed]</div>", 
    "prevInTime": 23645, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1316022073", 
    "canDelete": false, 
    "nextInTopic": 23647, 
    "prevInTopic": 23643, 
    "headers": {
        "inReplyToHeader": "PENBK25Qbk16eW53NEZ3LTNGQkhGOD1kK2VtaEQzZzdTT3ZYSjZ4M3VONXVqKytBUC1Wd0BtYWlsLmdtYWlsLmNvbT4=", 
        "messageIdInHeader": "PDNDQkUzQ0VCLTUyQ0EtNDI2Mi05RURCLTI4OERFQUE1MEIxNUBkaGVtZXJ5LmNvbT4=", 
        "referencesHeader": "PENBK25Qbk13YmZOdnhiaHFqV1Z5WFc3VUR0MlZNNVR6d1d6d0FpUkphSGtLcm5Iem14UUBtYWlsLmdtYWlsLmNvbT4gPENBK25Qbk15UVB3X2htQjVQWmpZNXRPN0xkaFN2WEprYjdObjlKRlpyZUIxVnk1UDhvd0BtYWlsLmdtYWlsLmNvbT4gPENBQ2ZiT3ZlTTZOTVBKREZuNUI5dXlvNWJjY0ZKeTErcld2czgzNzNjR0hodjcxd1ZXZ0BtYWlsLmdtYWlsLmNvbT4gPENBK25Qbk16eW53NEZ3LTNGQkhGOD1kK2VtaEQzZzdTT3ZYSjZ4M3VONXVqKytBUC1Wd0BtYWlsLmdtYWlsLmNvbT4="
    }
}