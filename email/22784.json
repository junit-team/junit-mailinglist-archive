{
    "numMessagesInTopic": 9, 
    "nextInTime": 22785, 
    "senderId": "HKKH96tbOVLQ7VSrRbWb8Y3bxLVdFCy79tCp8HNSJo89PXMqBbyO3ZbZU0HrYidKjnnGH0cyNDEAetm3GQvUrRodwSGpRUFs62Blug", 
    "systemMessage": false, 
    "subject": "Re: @BeforeClass method for DBUnit Dataset creation", 
    "from": "&quot;hdave321321&quot; &lt;hdave321321@...&gt;", 
    "authorName": "hdave321321", 
    "msgSnippet": "That is a compelling story -- thanks for taking the time to tell it. We use a best practice that each test class must have its own independent test data set.", 
    "msgId": 22784, 
    "profile": "hdave321321", 
    "topicId": 22776, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 453277943, 
    "messageBody": "<div id=\"ygrps-yiv-1256099605\">That is a compelling story -- thanks for taking the time to tell it.<br/>\n<br/>\nWe use a best practice that each test class must have its own independent test data set.  Right now we have only 8 test class and 8 test data sets.  But soon we&#39;ll have 50+ test classes and so we&#39;ll have 50+ test data sets.  Recall that Spring Test performs a rollback after every test method, so there are no dependencies between tests.<br/>\n<br/>\nIn your experience, is one data set per test *class* good enough?  It&#39;s unclear from your narrative if you are suggesting one data set per test *method* or just avoiding/minimizing integration testing altogether in favor of unit testing.<br/>\n<br/>\nI have found these DAO integration tests to be extremely helpful, given all the subtleties and magic surrounding Spring and Hibernate.<br/>\n<br/>\n<br/>\n<br/>\n <br/>\n<br/>\n<blockquote><span title=\"qreply\"> --- In <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a>, &quot;J. B. Rainsberger&quot; &lt;jbrains762@...&gt; wrote:<br/>\n&gt;<br/>\n&gt; hdave321321 wrote:<br/>\n&gt; <br/>\n&gt; &gt; My DAO integration tests are taking a long time to run.  I am using<br/>\n&gt; &gt; Spring Test which automatically does a transaction rollback after<br/>\n&gt; &gt; each test method.  However, I am also using DBUnit to load the exact<br/>\n&gt; &gt; same dataset before each test method via the @BeforeTransaction<br/>\n&gt; &gt; annotation.<br/>\n&gt; &gt;<br/>\n&gt; &gt; It has occured to me that I could save a lot of time if I load the<br/>\n&gt; &gt; DBUnit test data once per test class instead of once per test<br/>\n&gt; &gt; method.<br/>\n&gt; &gt;<br/>\n&gt; &gt; I&#39;ve not used the @BeforeClass and @AfterClass methods before, but<br/>\n&gt; &gt; apparently they require the annotated method to be static and this is<br/>\n&gt; &gt; interfering with my normal use of Spring dependency injection that<br/>\n&gt; &gt; provides an application context, data source, and other things I need<br/>\n&gt; &gt; to load the correct data set.<br/>\n&gt; &gt;<br/>\n&gt; &gt; Anyone experience this before?  What&#39;s a good way to address this<br/>\n&gt; &gt; problem?<br/>\n&gt; <br/>\n&gt; Let me tell you a story.<br/>\n&gt; <br/>\n&gt; In 2001 I worked on my first XP project at Toyota Canada in Toronto. We <br/>\n&gt; ran into exactly the same problem you describe here: we had several <br/>\n&gt; dozen tests, most of which inserted data in setUp() and rolled <br/>\n&gt; transactions back in tearDown(). Back then, of course, computers ran <br/>\n&gt; more slowly, so we were running at around 5-10 tests per second when we <br/>\n&gt; were lucky. We could see how when we added another 300 tests our test <br/>\n&gt; suite would take several minutes to run, and that just wasn&#39;t going to <br/>\n&gt; work. We decided to create a single test data set for the entire test <br/>\n&gt; suite, then used the tools of the time--DBUnit, in fact--to insert the <br/>\n&gt; data set at the start of the test run. For a few weeks, it worked great. <br/>\n&gt; Our test suite execution time dropped from minutes to tens of seconds <br/>\n&gt; which, back then, we could live with.<br/>\n&gt; <br/>\n&gt; Then something annoying happened.<br/>\n&gt; <br/>\n&gt; We added a new feature, which required putting data in a new table, <br/>\n&gt; which itself required adding a row to an old table to set up a foreign <br/>\n&gt; key relationship. We got the six new tests to run, but when we ran the <br/>\n&gt; entire suite just before checkin, 3 tests failed. We discovered that by <br/>\n&gt; adding a row to the parent table, we changed the expected result for <br/>\n&gt; three of our tests: they used to expect 6 rows, and now they needed to <br/>\n&gt; expect 7. We considered two options: split the test data into two sets, <br/>\n&gt; or change the expected results in the tests. We figured that the first <br/>\n&gt; option would slowly lead us back to loading test data for each test, so <br/>\n&gt; we chose the second option and changed the expected results.<br/>\n&gt; <br/>\n&gt; A couple of weeks later, it happened again. We added a feature that <br/>\n&gt; required putting data in a new table, which itself required adding rows <br/>\n&gt; to a few different existing tables to set up foreign key relationships. <br/>\n&gt; We got the eight new tests run, but when we ran the whole suite, 10 <br/>\n&gt; tests failed. We sighed, we checked what happened, and we updated the <br/>\n&gt; expected results on the old tests.<br/>\n&gt; <br/>\n&gt; A week later, it happened again. This time we had to change 26 tests. It <br/>\n&gt; took a day to do it accurately, because each &quot;fix&quot; required running an <br/>\n&gt; 8-minute test suite, and 26 times 8 is already over three hours.<br/>\n&gt; <br/>\n&gt; A week later, it happened again. This time we had to change 61 tests. It <br/>\n&gt; took three days. We saw where this was going.<br/>\n&gt; <br/>\n&gt; We split the test data back into sensible datasets, with each test <br/>\n&gt; loading the data it needed. Execution time increased, but maintenance <br/>\n&gt; time went to almost zero. We also figured out how to test more of the <br/>\n&gt; system without touching the database at all. Nowadays, when I work on <br/>\n&gt; such a project, only about 20-50 tests touch the database, and the rest <br/>\n&gt; run in memory. At today&#39;s machine speeds, I usually get 250-500 tests <br/>\n&gt; per second. In the ten seconds it takes for my mind to wander, I can run <br/>\n&gt; 15,000-30,000 tests. I can build a pretty good system for 15,000 tests.<br/>\n&gt; -- <br/>\n&gt; J. B. Rainsberger :: <a rel=\"nofollow\" target=\"_blank\" href=\"http://www.jbrains.ca\">http://www.jbrains.ca</a> ::<br/>\n&gt; <a rel=\"nofollow\" target=\"_blank\" href=\"http://www.thecodewhisperer.com\">http://www.thecodewhisperer.com</a><br/>\n&gt; </span></blockquote></div>", 
    "prevInTime": 22783, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1278084764", 
    "canDelete": false, 
    "nextInTopic": 22791, 
    "prevInTopic": 22783, 
    "headers": {
        "inReplyToHeader": "PDRDMkQwMzlGLjQwMTA2MDVAZ21haWwuY29tPg==", 
        "messageIdInHeader": "PGkwbDBxcyttNzdtQGVHcm91cHMuY29tPg=="
    }
}