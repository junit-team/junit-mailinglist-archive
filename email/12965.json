{
    "numMessagesInTopic": 4, 
    "nextInTime": 12966, 
    "senderId": "OoO9Va-2vYo9-Q2oj9CJUPrqX1zxhzOGGDUc9xJAfH1hLeyelkQx0gqee3_WSFuJhBtHptoynDSmZeIJv-oODHT8G2_A6gE", 
    "systemMessage": false, 
    "subject": "Re: [junit] JUnit test dependencies", 
    "from": "Chris Morris &lt;chrismo@...&gt;", 
    "authorName": "Chris Morris", 
    "msgSnippet": "... The bottom line is this: the tests should break if something is wrong. If the test for deleting a record doesn t even get off the ground because there s a", 
    "msgId": 12965, 
    "profile": "workmo", 
    "topicId": 12962, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 119663832, 
    "messageBody": "<div id=\"ygrps-yiv-1166240864\">k m wrote:<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt;Generically stated, should a test method&#39;s setUp() and tearDown() rely on an untested method? If not, how can we avoid it? Is there a way to enforce the sequence of test method runs?<br/>\n&gt;  <br/>\n&gt;<br/>\n </span></blockquote>The bottom line is this: the tests should break if something is wrong. <br/>\nIf the test for deleting a record doesn&#39;t even get off the ground <br/>\nbecause there&#39;s a problem inside the add record method, then it still <br/>\nbreaks, right? And vice-versa. Granted, with these dependencies, you&#39;ve <br/>\ngot potential for some situations that may be hard to figure out, or <br/>\ncases where one single problem causes many tests unnecessarily to break, <br/>\nbut the red flags will still be thrown as soon as a bug creeps in, and <br/>\nthat&#39;s the more important value.<br/>\n<br/>\nThe only real problems you have to look out for are cases where somehow <br/>\nthe code is broken, but the tests still pass.<br/>\n<br/>\nThe other piece of advice to come to mind is to have different methods <br/>\nfor adding and deleting that only the tests use -- don&#39;t re-use the <br/>\nproduction methods in your setUp()/tearDown(). I&#39;d heard once the MS <br/>\nExcel team has two calculation engines to solve similar dilemmas. The <br/>\nproduction one is complex and optimized, the testing one is simpler and <br/>\nslow -- a lot of duplicated effort, but the only real way to verify the <br/>\nresults of complex scenarios.<br/>\n<br/>\n-- <br/>\nChris<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://clabs.org/blogki\">http://clabs.org/blogki</a></div>", 
    "prevInTime": 12964, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1109395955", 
    "canDelete": false, 
    "nextInTopic": 0, 
    "prevInTopic": 12964, 
    "headers": {
        "inReplyToHeader": "PDIwMDUwMjI1MjAxNjIzLjI2NDYucW1haWxAd2ViNTAyMDYubWFpbC55YWhvby5jb20+", 
        "messageIdInHeader": "PDQyMjAwOUYzLjkwNTA5MDNAY2xhYnMub3JnPg==", 
        "referencesHeader": "PDIwMDUwMjI1MjAxNjIzLjI2NDYucW1haWxAd2ViNTAyMDYubWFpbC55YWhvby5jb20+"
    }
}