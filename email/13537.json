{
    "numMessagesInTopic": 55, 
    "nextInTime": 13538, 
    "senderId": "DAxiJleqNiuYTWpNcmf62vzhW9W7UlUZ8K8IhiI05yz5dZ6optMpQHM4lWjg5rs3HTa2K7aFg9ntncNBIaMBRTCLbKtjX29Gdg", 
    "systemMessage": false, 
    "subject": "RE: [junit] Re: DbUnit & ORM", 
    "from": "&quot;Cedric Beust&quot; &lt;cbeust@...&gt;", 
    "authorName": "Cedric Beust", 
    "msgSnippet": "... Ah ok.  Yes, this is also something I wanted to fix because what I was usually doing to ignore a test in JUnit is to rename it _test or comment it out.", 
    "msgId": 13537, 
    "profile": "cbeust", 
    "topicId": 13451, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 199443513, 
    "messageBody": "<div id=\"ygrps-yiv-1106822683\"><blockquote><span title=\"ireply\">&gt; From: <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a> [mailto:<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a>] On <br/>\n<br/>\n&gt; Ignored tests are always skipped, but not because another <br/>\n&gt; test failed but because the programmer set the test to be <br/>\n&gt; ignored, which is a kind of &quot;sleep&quot; mode.<br/>\n<br/>\n </span></blockquote>Ah ok.  Yes, this is also something I wanted to fix because what I was<br/>\nusually doing to ignore a test in JUnit is to rename it &quot;_test&quot; or comment<br/>\nit out.  I thought it was a bit silly and it made me realize that a testing<br/>\nframework should have two models:<br/>\n<br/>\n- A static model, which represents the business logic of your tests (the<br/>\ncode)<br/>\n- A dynamic model, which describes which test to run at a given time<br/>\n<br/>\nI saw no reason why a modification to the dynamic model (&quot;now I want to run<br/>\na different set of tests&quot;) should force me to change the static model (in<br/>\nJUnit, you will usually comment out or rename a few test methods, or modify<br/>\nyour suite() method).<br/>\n<br/>\nI actually  thought this was dangerous because you will comment out tests<br/>\nthat you might forget about later.<br/>\n<br/>\nThis is one of the reasons why I introduced the notion of &quot;groups&quot;, which<br/>\ncontain test methods.  Once you have defined them, you can specify which<br/>\ngroups to run dynamically (on the command line, in the IDE or in an XML<br/>\nfile).  You can also use annotations to specify that a certain test is<br/>\ndisabled, or create a certain group &quot;disabled&quot; or &quot;broken&quot; which will always<br/>\nbe ignored.  And if one day you want a list of all the tests currently<br/>\nignored, this information is available in the reports generated by TestNG.<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; Now to your test dependancies. I&#39;ll tell you how our tests <br/>\n&gt; are grouped in the suites.<br/>\n&gt; <br/>\n&gt; There is a JUnit test suite for every Eclipse project.<br/>\n&gt; Then we have a suite for each component in the projects. The <br/>\n&gt; components can have these groups of<br/>\n&gt; tests: persistance tests (whether entites are persisted and <br/>\n&gt; retrieved correctly according to meta data, including <br/>\n&gt; validation rule testing for these entities and entity <br/>\n&gt; factories), batch program tests (which either can be legacy <br/>\n&gt; data migration batch tests or fast lane reader batch tests), <br/>\n&gt; business logic tests (like ABC analysis, sales forecast, <br/>\n&gt; purchase proposals and so on), tests for utility classes and <br/>\n&gt; some other groups of tests (but we have no automated GUI tests).<br/>\n&gt; <br/>\n&gt; If persistance tests fail, then it would be no use to run all <br/>\n&gt; other tests. If tests for utility classes fail, then in many <br/>\n&gt; cases it is no use to run all other tests. If batch tests <br/>\n&gt; fail, it doesn&#39;t mean that business logic tests will fail and <br/>\n&gt; vice versa. This is a corse grained dependency of our tests. <br/>\n&gt; The fine grained test dependencies are much more of course.<br/>\n<br/>\n </span></blockquote>I believe this is a textbook example where TestNG would help you greatly<br/>\n(and I&#39;d be curious to hear how you pulled it off with JUnit).<br/>\n<br/>\nAs I said earlier, TestNG groups allow you to corelate test methods together<br/>\nin a looser way than with packages and classes.  Test methods can also<br/>\nbelong to several groups at the same time:<br/>\n<br/>\n@Test(groups = { &quot;functional&quot;, &quot;database&quot;, &quot;table.account&quot; })<br/>\npublic void insertIntoAccount() { ... }<br/>\n<br/>\nThis annotation flags this test as <br/>\n<br/>\n- Part of the functional (or acceptance) suite, which means it will be part<br/>\nof the nightly tests that exercise your entire application<br/>\n<br/>\n- It&#39;s also part of the database group, which means it does something with<br/>\nthe database.  If you make a modification to your front-end code, you<br/>\nprobably don&#39;t need to run it<br/>\n<br/>\n- More specifically, it states that it modifies the table ACCOUNT.  This<br/>\nway, if you make a modification to this table&#39;s schema, you can run only<br/>\nthese tests that touch this table.<br/>\n<br/>\nAnd as I mentioned above, groups are also used to calculate dependencies and<br/>\nguarantee that groups of methods (&quot;launch-server&quot;) are always run and<br/>\nsucceed before a next group of tests is run (&quot;servlet&quot;).<br/>\n<br/>\nPlease email me privately if you want to discuss this further as I don&#39;t<br/>\nwant to overwhelm this list with non-JUnit material.<br/>\n <br/>\n<blockquote><span title=\"ireply\"> &gt; In our team we all know that if persistance tests fail, we <br/>\n&gt; don&#39;t have to care about the business logic test results.<br/>\n<br/>\n </span></blockquote>That&#39;s one thing that bothers me about the absence of dependency support:<br/>\nhumans shouldn&#39;t have to figure this out, the testing framework should tell<br/>\nthem right away.<br/>\n<br/>\nWith JUnit, I noticed that people who read the test reports every morning no<br/>\nlonger really trust what they read:  when they see &quot;50 FAILURES&quot;, they<br/>\nalready know deep inside that there&#39;s probably much less &quot;real&quot; failures and<br/>\nthat the other ones are just cascading failures.  So they go to the logs and<br/>\ntry to figure out manually what &quot;really&quot; happened.<br/>\n<br/>\nDependent test methods allow the test framework to be much more accurate in<br/>\nits report and to say &quot;20 SUCCESSES, 1 FAILURE, 29 SKIPS&quot;.  When you read<br/>\nthis, you know right away where to look.<br/>\n <br/>\n<blockquote><span title=\"ireply\"> &gt; We really have a large project. If the tests reflect the code <br/>\n&gt; structure too close, then refactoring becomes very time <br/>\n&gt; consuming because it affects tests very much. Thats for <br/>\n&gt; example why it is recommended to only test public methods. <br/>\n<br/>\n </span></blockquote>I agree that it&#39;s a good practice in general, as long as you don&#39;t make it a<br/>\nholistic rule to &quot;never test private methods&quot;.  It&#39;s sometimes necessary, as<br/>\nit is sometimes necessary to add hooks in your code just to facilitate your<br/>\ntests.<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; My theoretical objection to maintain dependency information in <br/>\n&gt; the tests is that it is additional work to do and to <br/>\n&gt; maintain. If the dependency changes for the worse, the test <br/>\n&gt; dependency information (annotation) need to be changed. <br/>\n<br/>\n </span></blockquote>Agreed, that&#39;s a concern.  You need to use your judgment when you establish<br/>\nyour test dependency graph and you should probably be conservative when<br/>\ndoing so.<br/>\n<br/>\nI think coarse-grained dependencies make sense (&quot;only test the server if<br/>\nyou&#39;re sure it was launched successfully&quot;) but finer-grained ones should be<br/>\nlooked at carefully.<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; Besides this, if test group B is no longer dependent of test <br/>\n&gt; group A, then the tests pass although there is no dependency <br/>\n&gt; anymore. It is pure luck for a programmer to detect that test <br/>\n&gt; B is no longer dependent of test A. Only if a new dependency <br/>\n&gt; is created, the tests will fail. But if a dependency <br/>\n&gt; vanishes, the tests will not fail and will contain misleading <br/>\n&gt; dependency annotations. Isolated tests are more stable to <br/>\n&gt; change than dependent tests I think.<br/>\n<br/>\n </span></blockquote>There is certainy value in isolated tests and despite my strong support for<br/>\ndependent test methods, I am pretty sure that most tests out there do not<br/>\nneed dependency and are running fine in isolation.<br/>\n<br/>\nHaving said that, when you need dependency...  well, you really need it.<br/>\n <br/>\n<blockquote><span title=\"ireply\"> &gt; Don&#39;t get me wrong. I argued here against JUnit in favor of <br/>\n&gt; Design by Contract a few years ago. Now I like JUnit, which <br/>\n&gt; can apply to TestNG too, or not, who knows.<br/>\n<br/>\n </span></blockquote>No worries, it&#39;s a very interesting conversation.  I hope more people will<br/>\nweigh in.<br/>\n<br/>\n-- <br/>\nCÃ©dric<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://beust.com/testng\">http://beust.com/testng</a></div>", 
    "prevInTime": 13536, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1116260500", 
    "canDelete": false, 
    "nextInTopic": 13538, 
    "prevInTopic": 13533, 
    "headers": {
        "inReplyToHeader": "PDIwMDUwNTE2MTQ0NjE0LjY2MjU1LnFtYWlsQHdlYjYwMDI1Lm1haWwueWFob28uY29tPg==", 
        "messageIdInHeader": "PDIwMDUwNTE2MTYyMS5qNEdHTGV2NjAzMjYzMUAyMTYtMjM5LTQ1LTQuZ29vZ2xlLmNvbT4="
    }
}