{
    "numMessagesInTopic": 17, 
    "nextInTime": 13964, 
    "senderId": "X--Pg2ZOnf4rZemJKCm4g2Yki3PpYI7sS-oipT1NHkuzUDa1lIdgMjyYuJmo0qFANISzVx9D9NtM7404-lzIQUOGmIQe4nlC_HxW3iFfRg", 
    "systemMessage": false, 
    "subject": "Re: [junit] random testing with JUnit", 
    "from": "Elliotte Harold &lt;elharo@...&gt;", 
    "authorName": "Elliotte Harold", 
    "msgSnippet": "... I think we re in agreement here, but I don t think this is what the original poster was suggesting. I m OK with randomly selecting data from a large input", 
    "msgId": 13963, 
    "topicId": 13941, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 12653864, 
    "messageBody": "<div id=\"ygrps-yiv-1358944969\">Cedric Beust wrote:<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; I disagree.  A lot of programs work based on random generations, so it<br/>\n&gt; should come as no surprise that tests can do that as well, as long as the<br/>\n&gt; failure can be reproduced when it occurs.<br/>\n&gt; <br/>\n<br/>\n </span></blockquote>I think we&#39;re in agreement here, but I don&#39;t think this is what the <br/>\noriginal poster was suggesting. I&#39;m OK with randomly selecting data from <br/>\na large input set (too large to test exhaustively) for testing provided <br/>\nthat the selection is done prior to the construction of the unit test <br/>\nsuite. i.e. from the generated tests you want to pick out any tests that <br/>\nfail and explicitly add them to the unit test suite. This is a <br/>\nreasonable thing to do, but it&#39;s not something that JUnit really lends <br/>\nitself to.<br/>\n<br/>\nI think the original request was top randomly pick test data as part of <br/>\nthe test suite itself, and I think that&#39;s a bad idea. At worst you&#39;re <br/>\ngoing to see unreproducible failures. At best, you&#39;re going to get a <br/>\nfailure with enough information about the input data to enable you to <br/>\nhand construct a reproducible version if anybody&#39;s actually looking that <br/>\nclosely at the results, which often they aren&#39;t. For instance, if I busy <br/>\noptimizing and debugging in package foo I may ignore test failures that <br/>\nrandomly occur in package bar.<br/>\n<br/>\nAnother problem: the normal response to a test failure following a code <br/>\nchange is to look at that change and see how that modification caused <br/>\nthe problem. With random test data there&#39;s simply no guarantee that the <br/>\nlast change did indeed cause the test failure. the failure could have <br/>\nexisted completely independently of the change you made.<br/>\n<br/>\nYou can work around all these issues of course; but really, why should <br/>\nyou? None of this is what JUnit (or unit testing in general) was <br/>\ndesigned to do . There are simpler, easier ways to solve this problem <br/>\nthat don&#39;t involve running different tests every time you type &quot;java <br/>\njunit.text.ui.TestRunner foo.bar.TestSuite.&quot;<br/>\n<br/>\n-- <br/>\nElliotte Rusty Harold  <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:elharo@...\">elharo@...</a><br/>\nXML in a Nutshell 3rd Edition Just Published!<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://www.cafeconleche.org/books/xian3/\">http://www.cafeconleche.org/books/xian3/</a><br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://www.amazon.com/exec/obidos/ISBN=0596007647/cafeaulaitA/ref=nosim\">http://www.amazon.com/exec/obidos/ISBN=0596007647/cafeaulaitA/ref=nosim</a></div>", 
    "prevInTime": 13962, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1119109574", 
    "canDelete": false, 
    "nextInTopic": 13964, 
    "prevInTopic": 13962, 
    "headers": {
        "inReplyToHeader": "PDIwMDUwNjE4MTQyNi5qNUlFUURMdzAxNjEzOEAyMTYtMjM5LTQ1LTQuZ29vZ2xlLmNvbT4=", 
        "messageIdInHeader": "PDQyQjQ0MUM2LjYwMzA2MDdAbWV0YWxhYi51bmMuZWR1Pg==", 
        "referencesHeader": "PDIwMDUwNjE4MTQyNi5qNUlFUURMdzAxNjEzOEAyMTYtMjM5LTQ1LTQuZ29vZ2xlLmNvbT4="
    }
}