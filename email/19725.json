{
    "numMessagesInTopic": 48, 
    "nextInTime": 19726, 
    "senderId": "4ZWu3CN4_Q_jgbW-uMnbYhoJ_fICohPtJCJ7mR54JA0TosE2kA9S6637qGeIh8pVXy-TEaLOry3ed1SGmxA4Ss4fqvL5bWif", 
    "systemMessage": false, 
    "subject": "RE: [junit] RE: Assurance/CPU cycle ratio [branching from Re: Test Grouping/Partitioning]", 
    "from": "&quot;Kent Beck&quot; &lt;kentb@...&gt;", 
    "authorName": "Kent Beck", 
    "msgSnippet": "David, Efficient testing (in the assurance/CPU cycle or assurance/clock time sense) requires modular design and careful testing technique. The valuable moment ", 
    "msgId": 19725, 
    "profile": "kentlbeck", 
    "topicId": 19521, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 173198504, 
    "messageBody": "<div id=\"ygrps-yiv-547534060\">David,<br/>\n <br/>\nEfficient testing (in the assurance/CPU cycle or assurance/clock time sense)<br/>\nrequires modular design and careful testing technique. The valuable moment<br/>\nis when you can say, &quot;Y can&#39;t possibly be affected by how X is calculated.&quot;<br/>\nWhen you can say that (and be right :-), you can test X and Y separately.<br/>\nThe setup for each is likely to be cheaper than the setup for testing them<br/>\nboth together. Because the tests are cheaper, you can afford to be more<br/>\nthorough with each of X and Y.  I think I write fairly efficient tests but I<br/>\nhaven&#39;t been aware enough to clearly articulate my design process. <br/>\n <br/>\nI&#39;d love to help optimize a long-running industrial test suite. I suspect<br/>\nthat much of the effort would be spent trying refactorings that might lead<br/>\nto separately testable dimensions. I would want to be sure that each step<br/>\ndidn&#39;t reduce the assurance provided by the whole suite. Only when tests<br/>\nwere clearly redundant would I remove the slower running version.<br/>\n <br/>\nHas anyone here done any profiling of long-running test suites? I&#39;m curious<br/>\nwhat percentage of time is spent in setup/teardown versus actually running<br/>\nthe tests.<br/>\n <br/>\nMy vision is that 24-hour test suites will eventually go the way of<br/>\novernight compiles. To achieve this will require advances in design and<br/>\ntesting technique, and perhaps tooling as well.<br/>\n <br/>\nCheers,<br/>\n <br/>\nKent<br/>\n<br/>\n  _____  <br/>\n<br/>\nFrom: <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a> [mailto:<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a>] On Behalf Of<br/>\nDavid Jackman<br/>\nSent: Friday, July 27, 2007 7:48 AM<br/>\nTo: <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a><br/>\nSubject: [junit] RE: Assurance/CPU cycle ratio [branching from Re: Test<br/>\nGrouping/Partitioning]<br/>\n<br/>\n<br/>\n<br/>\nThis idea of an assurance/CPU cycle ratio is intriguing. Thinking of a<br/>\nparticular module where I spend most of my time, I have many hundreds of<br/>\nunit tests that do run fairly fast (several seconds), but are slow<br/>\nenough that I find myself not running them sometimes so as not to break<br/>\nmy momentum. The assurance/CPU cycle ratio concept would imply that it<br/>\nshould be possible to improve the ratio without decreasing the assurance<br/>\nI&#39;m getting from running the tests. <br/>\n<br/>\nWhat formulas or patterns did they use for improving this ratio? How<br/>\ndid they ensure that they weren&#39;t sacrificing assurance while improving<br/>\nperformance (i.e. open the code up for a potential bug in the future<br/>\nbecause a particular case is no longer being tested)?<br/>\n<br/>\n..David..<br/>\n<br/>\nFrom: junit@yahoogroups. &lt;mailto:junit%40yahoogroups.com&gt; com<br/>\n[mailto:junit@yahoogroups. &lt;mailto:junit%40yahoogroups.com&gt; com] On Behalf<br/>\nOf<br/>\nKent Beck<br/>\nSent: Thursday, July 26, 2007 4:38 PM<br/>\nTo: junit@yahoogroups. &lt;mailto:junit%40yahoogroups.com&gt; com<br/>\nSubject: [junit] Re: Test Grouping/Partitioning<br/>\n<br/>\nAll,<br/>\n<br/>\nIt seems clear to me that some sort of test classification scheme is a<br/>\nreasonable thing to add to JUnit. However, rather than simply copy one<br/>\nof<br/>\nthe models out there we&#39;re going to go back to first principles and try<br/>\nto<br/>\nderive a model for classification that is concise, useful, flexible,<br/>\nand,<br/>\nabove all, easy to use.<br/>\n<br/>\nI&#39;ve heard two purposes for classification:<br/>\n* Performance<br/>\n* Assumptions<br/>\n<br/>\nPerformance<br/>\n<br/>\nIf you have tests that run for longer than your attention span (my<br/>\nlimits<br/>\nare 1 second for the inner loop of programming and 10 minutes for<br/>\nintegration), running a subset of the tests can give you some assurance<br/>\nthat<br/>\nthe software is working. Classification is one way to reduce test run<br/>\ntime--just this one test, all tests in this class, all tests in this<br/>\npackage, all tests labeled &quot;quick&quot;, etc.<br/>\n<br/>\nThere are other ways of reducing test run time. For example, you could<br/>\nhave<br/>\na runner that runs 1 second worth of the tests that have failed most<br/>\nrecently or a runner that runs half a second of recently failed tests<br/>\nplus<br/>\nhalf a second of randomly selected tests.<br/>\n<br/>\nIn the end I think the systemic solution to test run times is to improve<br/>\ndesign and testing techniques to dramatically increase the assurance/CPU<br/>\ncycle ratio. <br/>\n<br/>\nI remember a friend&#39;s story of an early project that used tests<br/>\nextensively.<br/>\nAfter three years they had a carefully tuned suite that took ten minutes<br/>\nto<br/>\nrun. When the test runtime increased beyond ten minutes, they would work<br/>\non<br/>\nthe design of the system and/or the design of the tests to improve the<br/>\nassurance/CPU cycle ratio and get the runtime back under ten minutes.<br/>\nThen<br/>\nmost of the original team left. <br/>\n<br/>\nA few years later my friend was shown the system. The programmer proudly<br/>\nexplained that the test suites now took 24 hours to run, even though the<br/>\nsystem had grown little in functionality. They had stopped paying<br/>\nattention<br/>\nto designing for testability. Every time they added a new axis of<br/>\nvariability they blindly ran the cross product of the existing tests<br/>\nwith<br/>\nall the alternatives for the new axis. Yes they had more tests, but A/C<br/>\nhad<br/>\ndropped by several orders of magnitude.<br/>\n<br/>\nIn short, I see using classification to reduce test runtime as a bandage<br/>\nmasking the real problem which is low A/C. Using classification to<br/>\nreduce<br/>\ntest runtime really is a hack and I hope people will continue working to<br/>\nimprove design for testability. We will still provide some<br/>\nclassification<br/>\nmechanism, but that doesn&#39;t make it not a hack.<br/>\n<br/>\nAssumptions<br/>\n<br/>\nThe second reason I&#39;ve heard for classification is to avoid a slew of<br/>\nmisleadingly failing tests. If my development machine doesn&#39;t have<br/>\naccess to<br/>\nthe database, then if I run the database tests I&#39;ll get a bunch of<br/>\nfailures<br/>\neven though the system is really working (or, to be more precise, I<br/>\ndon&#39;t<br/>\nhave any information about whether the system is really working or not).<br/>\n<br/>\nClassification is one way to express assumptions. When I say<br/>\n&quot;@Test(groups =<br/>\n{&quot;database&quot;})&quot; I have declared something about this test. However, this<br/>\nexpression seems limited and error-prone to me. I&#39;d prefer to have the<br/>\npower<br/>\nof a programming language to express my assumptions.<br/>\n<br/>\nIn the JUnit 4.4 you can use assumeThat() to express assumptions. For<br/>\nexample, you can say:<br/>\n<br/>\npublic class DatabaseTest {<br/>\n@BeforeClass public static void isDatabaseAccessible() {<br/>\nUser result= Database.login(&quot;kent&quot;);<br/>\nassumeThat(not(isError(result));<br/>\n}<br/>\n...<br/>\n}<br/>\n<br/>\nThis is a bit of a workaround because runner don&#39;t yet handle failed<br/>\nassumptions as anything other than successful tests, but it gives you a<br/>\nricher language to express assumptions than a textual classification<br/>\nscheme.<br/>\n<br/>\nThe Point<br/>\n<br/>\nSo now the point of this long post. Are there other uses of<br/>\nclassification<br/>\nthat I&#39;ve missed? Is the above way of expressing assumptions (or<br/>\nsomething<br/>\nderived from it like an explicit @Assumption) sufficient?<br/>\n<br/>\nRegards,<br/>\n<br/>\nKent Beck<br/>\nThree Rivers Institute<br/>\n<br/>\n[Non-text portions of this message have been removed]<br/>\n<br/>\n[Non-text portions of this message have been removed]<br/>\n<br/>\n<br/>\n<br/>\n <br/>\n<br/>\n<br/>\n[Non-text portions of this message have been removed]</div>", 
    "prevInTime": 19724, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1186621035", 
    "canDelete": false, 
    "nextInTopic": 19726, 
    "prevInTopic": 19693, 
    "headers": {
        "inReplyToHeader": "PDVDRDM3QjZFMDkwNDU0NDg5QzVGQzE1QjlCNEI1QjE5MTg5OTM1QHNsY2VzMDIuYWQuZmFzdC5ubz4=", 
        "messageIdInHeader": "PDAxOGUwMWM3ZGEyMCQzYmNhZTVmMCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPg==", 
        "referencesHeader": "PDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPiA8NUNEMzdCNkUwOTA0NTQ0ODlDNUZDMTVCOUI0QjVCMTkxODk5MzVAc2xjZXMwMi5hZC5mYXN0Lm5vPg=="
    }
}