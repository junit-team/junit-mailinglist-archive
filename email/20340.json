{
    "numMessagesInTopic": 12, 
    "nextInTime": 20341, 
    "senderId": "fzeoLUm2Bg6fZ8LljaZBb-3jf2HGIKTNwN2O-J-ixupo3t0CDGlkdB2OHybW0M9X0qFRknGqa3ov01I53rROygK9Hel2Gsh-", 
    "systemMessage": false, 
    "subject": "Re: Scope of the unit test case", 
    "from": "&quot;nat_pryce&quot; &lt;nat.pryce@...&gt;", 
    "authorName": "nat_pryce", 
    "msgSnippet": "... No.  In one project they ran in about an hour. In my current project in about 30 minutes.  That includes building deployable packages from scratch, running", 
    "msgId": 20340, 
    "profile": "nat_pryce", 
    "topicId": 20323, 
    "spamInfo": {
        "reason": "6", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 216973656, 
    "messageBody": "<div id=\"ygrps-yiv-1125404616\">--- In <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a>, &quot;J. B. Rainsberger&quot; &lt;jbrains762@...&gt; <br/>\n<blockquote><span title=\"ireply\"> &gt; Did those teams reach the point where end-to-end tests took more than  <br/>\n&gt; overnight to run? <br/>\n<br/>\n </span></blockquote>No.  In one project they ran in about an hour. In my current project<br/>\nin about 30 minutes.  That includes building deployable packages from<br/>\nscratch, running unit tests, dropping, recreating and upgrading the<br/>\ndatabase, dropping and recreating queues and topics, deploying the<br/>\nserver into a production-like environment, starting the client and<br/>\nthen sending JMS messages through the system and interacting with the<br/>\nclient by controlling mouse and keyboard or getting web reports from<br/>\nthe server.<br/>\n<br/>\n30 minutes does feel a bit too long, but has not been a massive<br/>\nproblem so far. We have made an effort to make the end-to-end tests<br/>\nrun faster when we find them to be slow as we have built up the<br/>\napplication.<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; When that happens, I see teams starting to cherry- <br/>\n&gt; pick their end-to-end tests, writing only the easy ones that are  <br/>\n&gt; likely already to pass, and that&#39;s the point at which integration  <br/>\n&gt; defects leak in by the ton.<br/>\n<br/>\n </span></blockquote>It sounds like an education issue.  Developers should *always* watch a<br/>\ntest fail first before implementing the code to make it pass.  They<br/>\nshould rarely be writing tests that can pass first time and, if they<br/>\ndo, they should break the code to ensure that the test fails as expected.<br/>\n<br/>\nIf I found that developers were skimping on testing I&#39;d make an effort<br/>\nto speed up the build, e.g. by running the tests in parallel in a<br/>\nbuild grid and maybe adding more monitoring and management access<br/>\npoints to the system.<br/>\n<br/>\nWe use the Team City CI server, which makes it very easy to set up a<br/>\nbuild grid of multiple build machines coordinated by a single server<br/>\nthat monitors the source repository.<br/>\n<br/>\nOn various projects we have moved scheduling out of the app itself and<br/>\nadded synchronisation messages and monitoring APIs so that external<br/>\ntests can get feedback on the state of the application as fast as<br/>\npossible.  They have also turned out to be useful in production for<br/>\nmonitoring system state.<br/>\n<br/>\n--Nat</div>", 
    "prevInTime": 20339, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1204107650", 
    "canDelete": false, 
    "nextInTopic": 0, 
    "prevInTopic": 20339, 
    "headers": {
        "inReplyToHeader": "PEY4Qjg3OTJFLTVDOEItNEIwMC1CNzk1LTI4MTE4QjAzQ0ZBMUBnbWFpbC5jb20+", 
        "messageIdInHeader": "PGZxM2RpMis2dGJjQGVHcm91cHMuY29tPg=="
    }
}