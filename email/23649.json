{
    "numMessagesInTopic": 13, 
    "nextInTime": 23650, 
    "senderId": "xhkhbtEAHH5t7CEjq3RfTi3dSzfoIBr0WrtLqPdrmXMr3-cS1ZgqLC0tpzUpGQKeCyWYe6p0wnUSHzUriavTTxi5MZ3Ec6kL4dPhlnY", 
    "systemMessage": false, 
    "subject": "Re: [junit] Feature request: @Assumes", 
    "from": "Charlie Poole &lt;charliepoole@...&gt;", 
    "authorName": "Charlie Poole", 
    "msgSnippet": "Hi Dale, I think it s an overinterpretation to call this a dependency. The syntax merely says that the test makes an assumption. Given such an assumption, the", 
    "msgId": 23649, 
    "profile": "cpoole98370", 
    "topicId": 23636, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 472478494, 
    "messageBody": "<div id=\"ygrps-yiv-344846205\">Hi Dale,<br/>\n<br/>\nI think it&#39;s an overinterpretation to call this a dependency. The syntax<br/>\nmerely says<br/>\nthat the test makes an assumption. Given such an assumption, the framework<br/>\nmight do a number of things, only one of which is to treat the connection as<br/>\na dependency.<br/>\n<br/>\nIn my own work - which of course is not junit-related - I&#39;m looking ways to<br/>\nspecify relations like this *without* calling for any specific behavior on<br/>\nthe<br/>\npart of the framework.<br/>\n<br/>\nOf course, the &quot;obvious&quot; and perhaps simplest implementation is to run<br/>\nthe &quot;assumed&quot; test first and skip the test using the assume in the case<br/>\nwhere it fails. But I like the idea that the user might express known or<br/>\nbelieved-to-be-true logical relations among tests while the framework<br/>\nwould be free to make use of that information in ways not necessarily<br/>\npredictable by the user.<br/>\n<br/>\nAs an example, imagine a framework that gave a message like<br/>\n&quot;You stated that TestA assumes TestB but TestA passed even<br/>\nthough TestB failed.&quot;<br/>\n<br/>\nCharlie<br/>\n<blockquote><span title=\"qreply\"> On Wed, Sep 14, 2011 at 10:41 AM, Dale Emery &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:dale@...\">dale@...</a>&gt; wrote:<br/>\n<br/>\n&gt; **<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; Hi Stephen and all,<br/>\n&gt;<br/>\n&gt; &gt; Nope not a mock at all.<br/>\n&gt; &gt;<br/>\n&gt; More like TestNG&#39;s &quot;dependsOnMethods&quot; feature.<br/>\n&gt;<br/>\n&gt; I understand your desire for this. I also understand the JUnit guys&#39;<br/>\n&gt; reluctance to implement it. My intermediate-ish experience with TestNG<br/>\n&gt; leaves me with the conclusion that inter-test dependencies lead to madness.<br/>\n&gt; To be fair, I had already concluded that before working with clients who<br/>\n&gt; insisted on specifying inter-test dependencies.<br/>\n&gt;<br/>\n&gt; My first half-baked thought is to use a Rule to prevent running methods<br/>\n&gt; that depend on another method that has already failed. But that would work<br/>\n&gt; only if the tests were run in the appropriate order.<br/>\n&gt;<br/>\n&gt; So my next half-baked thought is to write a custom Runner that builds the<br/>\n&gt; dependency graph and sequences the tests accordingly. Then either the runner<br/>\n&gt; or a rule could decide whether to run a test. I&#39;m confident that a runner<br/>\n&gt; could do what you want, but that requires delving into the arcane bits of<br/>\n&gt; JUnit.<br/>\n&gt;<br/>\n&gt; A final half-baked thought: What if you ran all the tests, then used the<br/>\n&gt; dependency graph only to mark the results somehow, so as to highlight the<br/>\n&gt; tests on which others depend. If you see a swarm of failures, and the<br/>\n&gt; display indicates that some common prerequisite test also failed, that would<br/>\n&gt; aid your investigation.<br/>\n&gt;<br/>\n&gt; I&#39;ve seen situations where some prerequisite test fails, but some of the<br/>\n&gt; dependent tests pass. Sometimes the prerequisite test is lying to me (and I<br/>\n&gt; need to fix that). Sometimes the dependency is over-specified--the dependent<br/>\n&gt; test doesn&#39;t depend on everything that the prerequisite test tests (which<br/>\n&gt; means I need to refactor the prerequisite test and the dependency<br/>\n&gt; specifications). Sometimes it means that the prerequisite test fails<br/>\n&gt; intermittently (which means I need to track down the uncontrolled factors<br/>\n&gt; that affect the test).<br/>\n&gt;<br/>\n&gt; Skipping the dependent tests hides that information. Running them and<br/>\n&gt; marking them would highlight that<br/>\n&gt;<br/>\n&gt; Dale<br/>\n&gt;<br/>\n&gt; --<br/>\n&gt; Dale Emery<br/>\n&gt; Consultant to software teams and leaders<br/>\n&gt; <a rel=\"nofollow\" target=\"_blank\" href=\"http://dhemery.com\">http://dhemery.com</a><br/>\n&gt;<br/>\n&gt; [Non-text portions of this message have been removed]<br/>\n&gt;<br/>\n&gt;  <br/>\n&gt;<br/>\n<br/>\n<br/>\n[Non-text portions of this message have been removed] </span></blockquote></div>", 
    "prevInTime": 23648, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1316144490", 
    "canDelete": false, 
    "nextInTopic": 23650, 
    "prevInTopic": 23648, 
    "headers": {
        "inReplyToHeader": "PDNDQkUzQ0VCLTUyQ0EtNDI2Mi05RURCLTI4OERFQUE1MEIxNUBkaGVtZXJ5LmNvbT4=", 
        "messageIdInHeader": "PENBSis9ZmpoaCtlOXlRdFR6R0VGTG1OVVN3PVpSSDd4QVpaTVR2V0FTaTRuK1lPREFaZ0BtYWlsLmdtYWlsLmNvbT4=", 
        "referencesHeader": "PENBK25Qbk13YmZOdnhiaHFqV1Z5WFc3VUR0MlZNNVR6d1d6d0FpUkphSGtLcm5Iem14UUBtYWlsLmdtYWlsLmNvbT4JPENBK25Qbk15UVB3X2htQjVQWmpZNXRPN0xkaFN2WEprYjdObjlKRlpyZUIxVnk1UDhvd0BtYWlsLmdtYWlsLmNvbT4JPENBQ2ZiT3ZlTTZOTVBKREZuNUI5dXlvNWJjY0ZKeTErcld2czgzNzNjR0hodjcxd1ZXZ0BtYWlsLmdtYWlsLmNvbT4JPENBK25Qbk16eW53NEZ3LTNGQkhGOD1kK2VtaEQzZzdTT3ZYSjZ4M3VONXVqKytBUC1Wd0BtYWlsLmdtYWlsLmNvbT4JPDNDQkUzQ0VCLTUyQ0EtNDI2Mi05RURCLTI4OERFQUE1MEIxNUBkaGVtZXJ5LmNvbT4="
    }
}