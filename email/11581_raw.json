{
    "numMessagesInTopic": 28, 
    "nextInTime": 11582, 
    "senderId": "q0GbnF2tuHvstFSZURYkGTM1ZEYB2klLMrteEAEQ4oXYk2Fy14V70X_xkjtYp0H0wX37AHXwOQfgGOrZucogixMtEAJktPSBiw", 
    "systemMessage": false, 
    "subject": "Re: [junit] a test framework to codify levelizaton?", 
    "from": "Vlad Roubtsov &lt;vladrimp@...&gt;", 
    "authorName": "Vlad Roubtsov", 
    "msgSnippet": "I ve waited to get some data from others before replying. It appears that what I had in mind were testcases more functional in nature. In my experience on a", 
    "msgId": 11581, 
    "rawEmail": "Return-Path: &lt;vladrimp@...&gt;\r\nX-Sender: vladrimp@...\r\nX-Apparently-To: junit@yahoogroups.com\r\nReceived: (qmail 23583 invoked from network); 19 Jul 2004 14:02:32 -0000\r\nReceived: from unknown (66.218.66.166)\n  by m2.grp.scd.yahoo.com with QMQP; 19 Jul 2004 14:02:32 -0000\r\nReceived: from unknown (HELO web50304.mail.yahoo.com) (206.190.38.58)\n  by mta5.grp.scd.yahoo.com with SMTP; 19 Jul 2004 14:02:32 -0000\r\nMessage-ID: &lt;20040719140131.96103.qmail@...&gt;\r\nReceived: from [24.243.241.114] by web50304.mail.yahoo.com via HTTP; Mon, 19 Jul 2004 07:01:31 PDT\r\nDate: Mon, 19 Jul 2004 07:01:31 -0700 (PDT)\r\nTo: junit@yahoogroups.com\r\nIn-Reply-To: &lt;40F8A4F7.8090506@...&gt;\r\nMIME-Version: 1.0\r\nContent-Type: text/plain; charset=us-ascii\r\nX-eGroups-Remote-IP: 206.190.38.58\r\nFrom: Vlad Roubtsov &lt;vladrimp@...&gt;\r\nSubject: Re: [junit] a test framework to codify levelizaton?\r\nX-Yahoo-Group-Post: member; u=130143637\r\nX-Yahoo-Profile: vlad_r333\r\n\r\nI&#39;ve waited to get some data from others before\nreplying. It appears that what I had in mind were\ntestcases more functional in nature. In my experience\non a ~1GHz desktop a testsuite with 100-200 testcases\nwill take from 2 to 5 minutes. This translates into\n1-2 seconds per testcase.\n\nThe cost usually comes from a certain mix of CPU and\nJDBC utilization. The company I work for provides most\nof its high-value software via &quot;engines&quot; that operate\non complex &quot;models&quot;. The models are compiled from db\ndata or XML input and to get any kind of &quot;data/path\ncoverage&quot; in the engines/models they need to be\nexercised with a large number of different inputs. \n\n5 minutes seems to be about the threshold where team\nmembers can&#39;t help it and start cheating by removing\nsome testcases from their own dev runs. This sometimes\ntranslates into checkin errors because parts of the\ntestsuite develop failures not noticed until later.\n\nRegarding the actual method for inferring\ndependencies, I had a couple of ideas:\n\n(a) rely on explict markup from the developer(s).\nJavadoc pseudo-tags and real J2SE 1.5 metadata tags.\nThis has the advantage of being at a higher level of\nabstraction than mere .class dependencies if\nnecessary. However, if tagging is in the hands of more\nthan one architect on the team, some sort of an\nagreement on tag semantics/metadata would need to be\nestablished and that seems like a weakness.\n\n(b) go the low level route of analyzing .class\ndependencies. I wouldn&#39;t use reflection for this (that\ndata is insufficient) but rather rely on .class\ncontent for computing dependencies. I happen to have\nsome direct experience in this area and this can be\ndone very efficiently (sub-1ms per class). If I were\nto imagine a test suite runner that starts by scanning\nthe classpath to compute levelization this way, I\ndon&#39;t think there would be a delay more than ~1-2\nseconds per every 1000 classes, which is quite\nacceptable.\n\nOf course, the second option hits the usual problem of\nnot knowing about reflective and\nClass.forName()invocations... Anyway, I was wondering\nif there was a project tackling this somewhere.\n\nVlad.\n\n--- &quot;J. B. Rainsberger&quot; &lt;jbrains@...&gt; wrote:\n&gt; Vlad Roubtsov wrote:\n&gt; \n&gt; &gt; On any but the trivial projects the number of\n&gt; &gt; testcases quickly exceeds 100-200+. It usually\n&gt; takes a\n&gt; &gt; noticeable time to run them all.\n&gt; \n&gt; Can you quantify this? GSBase, for example, runs\n&gt; tests at approximately \n&gt; 100/second, and that&#39;s my usual performance goal for\n&gt; tests. On my most \n&gt; recent project, I separated tests that required\n&gt; expensive, external \n&gt; resources (there were about 10) from tests than ran\n&gt; entirely in memory \n&gt; (there were about 400). The in-memory tests ran in\n&gt; about 6 seconds.\n&gt; \n&gt; Is this &quot;noticeable&quot; by your standards? I&#39;d merely\n&gt; like some extra context.\n&gt; \n&gt;  &gt; It is also less\n&gt; &gt; efficient to do so because it ignores the idea of\n&gt; &gt; levelization (from John Lakos&#39; underappreciated\n&gt; book\n&gt; &gt; &quot;Large Scale C++ Software Design&quot;). In incremental\n&gt; dev\n&gt; &gt; mode it would be more efficient to execute only\n&gt; the\n&gt; &gt; testcases that correspond to the product\n&gt; package(s)\n&gt; &gt; that&#39;s just changed (and the dependency closure\n&gt; &gt; thereof) AND execute them in increasing level\n&gt; numbers\n&gt; &gt; (reverse package dependency topological order).\n&gt; \n&gt; This is a great idea, however, computing the\n&gt; complete dependency closure \n&gt; is awfully tricky. For most algorithms that attempt\n&gt; to do this, I can \n&gt; load a class through reflection and use it, breaking\n&gt; the algorithm&#39;s \n&gt; assertion that it correctly computes the runtime\n&gt; dependency closure. I&#39;m \n&gt; not saying it&#39;s impossible -- although it might be\n&gt; -- but I am doubtful \n&gt; that any existing tool does this adequately and\n&gt; could be integrated into \n&gt; Eclipse, for example.\n&gt; \n&gt; &gt; A tool/framework that enforces test (sub)suite\n&gt; &gt; execution in increasing level numbers would seem\n&gt; like\n&gt; &gt; the next evolutionary step after naive TDD. Does\n&gt; &gt; anyone know of such a tool? The testcase-&gt;app\n&gt; package\n&gt; &gt; assignment could be done by simply placing\n&gt; testcases\n&gt; &gt; in the relevant package (common practice already\n&gt; &gt; anyway) or by something like Java 1.5 metadata\n&gt; &gt; tagging.\n&gt; \n&gt; I&#39;m not aware of anything, but if it exists, the\n&gt; C#/.NET world would be \n&gt; a likely first place to look. They&#39;ve had metadata\n&gt; tagging longer than \n&gt; Java folks have.\n&gt; \n&gt; &gt; There are tools to analyze existing package\n&gt; &gt; dependencies, but I am not aware of a test\n&gt; framework\n&gt; &gt; to actually relate that data to testcase execution\n&gt; &gt; ordering.\n&gt; \n&gt; Those tools likely only analyze compile-time\n&gt; (structural) dependecies, \n&gt; and as I wrote above, it would be all too easy to\n&gt; exhibit a runtime \n&gt; dependency that such an analyzer would miss. The\n&gt; result is that runtime \n&gt; behavior might change without the analyzer knowing\n&gt; to run all the \n&gt; appropriate tests.\n&gt; \n&gt; I am admittedly shaky on the theory, and welcome\n&gt; being proven wrong, but \n&gt; I have this vague notion that I&#39;m right.\n&gt; -- \n&gt; J. B. Rainsberger,\n\n\n\t\t\n__________________________________\nDo you Yahoo!?\nVote for the stars of Yahoo!&#39;s next ad campaign!\nhttp://advision.webevents.yahoo.com/yahoo/votelifeengine/\n\n\n", 
    "profile": "vlad_r333", 
    "topicId": 11558, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 130143637, 
    "prevInTime": 11580, 
    "contentTrasformed": false, 
    "postDate": "1090245691", 
    "canDelete": false, 
    "nextInTopic": 11583, 
    "prevInTopic": 11578, 
    "headers": {
        "inReplyToHeader": "PDQwRjhBNEY3LjgwOTA1MDZAcm9nZXJzLmNvbT4=", 
        "messageIdInHeader": "PDIwMDQwNzE5MTQwMTMxLjk2MTAzLnFtYWlsQHdlYjUwMzA0Lm1haWwueWFob28uY29tPg=="
    }
}