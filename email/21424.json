{
    "numMessagesInTopic": 39, 
    "nextInTime": 21425, 
    "senderId": "nrIq0bJW9BLKopqeRDQajhTMxlia-xVt6I7LvpLLt_1YNgdF3t8LMsAfBn64-USO77gc6JvZs0XCbMF7YvPJzIe6Ly6yfFA", 
    "systemMessage": true, 
    "subject": "Re: A case for adding logging of assertions to junit", 
    "from": "&quot;rsgmxw&quot; &lt;markwilhelm@...&gt;", 
    "authorName": "rsgmxw", 
    "msgSnippet": "One thing about the logging of assertions is reporting on the Actual/Observed results. I work at a company that makes Medical Devices. The FDA, as we re told", 
    "msgId": 21424, 
    "profile": "rsgmxw", 
    "topicId": 20531, 
    "spamInfo": {
        "reason": "6", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 98194823, 
    "messageBody": "<div id=\"ygrps-yiv-871886980\">One thing about the &quot;logging of assertions&quot; is reporting on the Actual/Observed results. I work at a company that makes Medical Devices. The FDA, as we&#39;re told by QA, requires the deposition of all tests. So even Pass&#39;ing tests must have their actual results reported on. We do this currently with manual/human tests.<br/>\n<br/>\nIf the report could say something like:<br/>\nTest ID Status Expected        Actual<br/>\n123       Pass  Smith           Smith<br/>\n456       Pass  Value &gt; 10      12<br/>\n789       Fail  Value = &quot;abc&quot;   xyz<br/>\n...<br/>\n<br/>\nThis report would be stored (for many years) for audit purposes.<br/>\n<br/>\nNow being a newbie, maybe there is a way to do this I don&#39;t know about - but very useful.<br/>\n<br/>\nMark<br/>\n<br/>\n<br/>\n<blockquote><span title=\"qreply\"> --- In <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a>, &quot;toalexsmail&quot; &lt;toalexsmail@...&gt; wrote:<br/>\n&gt;<br/>\n&gt; --- In <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a>, Robert Wenner &lt;robert.wenner@&gt; wrote:<br/>\n&gt; &gt;<br/>\n&gt; &gt; On Monday 09 June 2008 21:18, CÃ©dric Beust  wrote:<br/>\n&gt; &gt; &gt; &gt; If I have to go through umpteen thousand lines of log, I may as well<br/>\n&gt; &gt; &gt; &gt; test everything manually.<br/>\n&gt; &gt; &gt;<br/>\n&gt; &gt; &gt; Nobody says you have to, but the fact that your tests pass doesn&#39;t<br/>\n&gt; &gt; &gt; guarantee that you are testing what you think you are testing.<br/>\n&gt; &gt; <br/>\n&gt; &gt; Well. If the log is important, I have to go through it, or I miss <br/>\n&gt; &gt; something important. If it is not important (and I don&#39;t have to go <br/>\n&gt; &gt; through it) I can skip it altogether. So what do you mean when you<br/>\n&gt; say I <br/>\n&gt; &gt; don&#39;t have to go through it?<br/>\n&gt; &gt; <br/>\n&gt; <br/>\n&gt; I have read carefully all the posts so far and I tend to agree with<br/>\n&gt; Robert. I am wonder whether I miss something important too.<br/>\n&gt; I want to be clear, so I will take one step backward. What is the MAIN<br/>\n&gt; purpose of JUnit? The answer is to be able to write AUTOMATIC unit<br/>\n&gt; test. Unit test should be written is the correct way, that is<br/>\n&gt; correctly design. This has nothing to do with logging. Making unit<br/>\n&gt; test AUTOMATIC contradict using logging.<br/>\n&gt; <br/>\n&gt; &lt;you can skip the this paragraph&gt;<br/>\n&gt; I want to step aside for a while. Let assume that you&#39;re not using<br/>\n&gt; JUnit at all and write small main function to test. I don&#39;t want to<br/>\n&gt; counter why you shouldn&#39;t do this, let focus on what tools you do use<br/>\n&gt; in this approach. In the most cases you will add System.out both to<br/>\n&gt; the code and to the main. If you&#39;re using C++, for instance, you will<br/>\n&gt; use preprocessor to switch on or off these output to the console. More<br/>\n&gt; advance option will be to use logging mechanism and to change it<br/>\n&gt; configuration depends on the environment your program run (that is to<br/>\n&gt; turn on many of your log statement only in development). Everything is<br/>\n&gt; great until your program is actually fails. Again, from the experience<br/>\n&gt; it is almost always the case that existing System.outs are not enough,<br/>\n&gt; that you need more information or you should add some more output<br/>\n&gt; early in the code. So, in this point you have to option to run your<br/>\n&gt; program AGAIN with debugger or to add more System.outs and to run it<br/>\n&gt; as is. In both cases it can be the case that you should rerun your<br/>\n&gt; program again (if you use debugger you could simply not pointed out<br/>\n&gt; when some data changed and in the System.out case you can figure out<br/>\n&gt; that you need more System.outs).<br/>\n&gt; <br/>\n&gt; From the paragraph above one should conclude that when one write unit<br/>\n&gt; test there is 2 different phases. First is to write them down in the<br/>\n&gt; hope that everything will be ok (it doesn&#39;t mean, that you design<br/>\n&gt; should be poor or you shouldn&#39;t supply appropriate messages to assert<br/>\n&gt; statements etc) and the second phase is to rerun your test if your<br/>\n&gt; test fails. Lets see how logging will help you.<br/>\n&gt; <br/>\n&gt; In the first phase I see the only purpose using logs is for &#39;sanity<br/>\n&gt; check&#39; that is to ensure that you actually test what your think is you<br/>\n&gt; test. If you want to make something more than just &#39;sanity check&#39; you<br/>\n&gt; should write unit test to your unit test, that is pretty silly.<br/>\n&gt; Moreover, you need to make such &#39;sanity check&#39; only when you actually<br/>\n&gt; write this test.  For this purpose logging is appropriate approach, IMHO.<br/>\n&gt; <br/>\n&gt; In the second phase, when you rerun your unit test when it fails, you<br/>\n&gt; should consider to add more assert statement and more clearly<br/>\n&gt; diagnostic messages first. When you done and you don&#39;t see how to<br/>\n&gt; improve the design (recall I consider that design is correct) you can<br/>\n&gt; add log statement manually. But in this case they will not be part of<br/>\n&gt; new mechanism, because no more asserts will be added. So this new<br/>\n&gt; feature will not be in use!<br/>\n&gt; <br/>\n&gt; Using logging in the assert statement ONLY for &#39;sanity check&#39; is<br/>\n&gt; overkill, I think. As for me I make such &#39;sanity check&#39; in the<br/>\n&gt; following way. First of all, I use log4j MANUALLY that is as addition<br/>\n&gt; to JUnit asserts. They don&#39;t duplicate what asserts does they supply<br/>\n&gt; additional information, such as what assertion was already done. In<br/>\n&gt; this case when assertion will fail afterwards I can look on the log to<br/>\n&gt; see in what part of unit test it happened and what tests passed. I go<br/>\n&gt; even further and use JDK 1.4 assert statement to document<br/>\n&gt; precondition, postcondition and invariants both in the code and in the<br/>\n&gt; unit test.<br/>\n&gt; <br/>\n&gt; The bottom line is that I see the sense using logs as a COMPLETION to<br/>\n&gt; the JUnit and only for &#39;sanity check&#39;. This use is not duplicates<br/>\n&gt; JUnit assert statements and could be written manually.<br/>\n&gt; </span></blockquote></div>", 
    "prevInTime": 21423, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1236728280", 
    "canDelete": false, 
    "nextInTopic": 21426, 
    "prevInTopic": 20586, 
    "headers": {
        "inReplyToHeader": "PGcybW5uMCtzdWZhQGVHcm91cHMuY29tPg==", 
        "messageIdInHeader": "PGdwNnRrbytyMnVlQGVHcm91cHMuY29tPg=="
    }
}