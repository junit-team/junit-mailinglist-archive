{
    "numMessagesInTopic": 48, 
    "nextInTime": 19688, 
    "senderId": "jSFVeB5qFm2jQKNNdb4IEfRWFZWVQRFEv6i3qMrwfrt2Pu-KQl6RrSKKsxZ9nruVCtyEKZcZqYb1dfXQbG52VWHUMFqPCWO8", 
    "systemMessage": false, 
    "subject": "Re: [junit] Re: Test Grouping/Partitioning", 
    "from": "&quot;Nat Pryce&quot; &lt;nat.pryce@...&gt;", 
    "authorName": "Nat Pryce", 
    "msgSnippet": "I ve just thought of another categorisation of tests: whether they are regression tests or work in progress. We write tests for the functionality to be", 
    "msgId": 19687, 
    "profile": "nat_pryce", 
    "topicId": 19521, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 216973656, 
    "messageBody": "<div id=\"ygrps-yiv-1679935320\">I&#39;ve just thought of another categorisation of tests: whether they are<br/>\nregression tests or work in progress.<br/>\n<br/>\nWe write tests for the functionality to be delivered in the upcoming<br/>\niteration.  Those tests will initially fail.  As we go through the iteration<br/>\nmore and more of them will pass as we complete the work.  However, we can&#39;t<br/>\nlet the failing tests stop us checking in changes.  So we categorise tests<br/>\nas &quot;work-in-progress&quot; or &quot;regression&quot;.  Work-in-progress tests are allowed<br/>\nto fail without breaking the CI build.  A failing regression test breaks the<br/>\nbuild and must be fixed immediately before further changes can be checked<br/>\nin.<br/>\n<br/>\nAt the end of the iteration, passing &quot;work-in-progress&quot; tests are<br/>\nrecategorised as regression tests.If new work requires changes to existing<br/>\nfunctionality, the regression tests for that  functionality are<br/>\nrecategorised as &quot;work-in-progress&quot; until the new work is done.<br/>\n<br/>\nAt the moment we just move tests between different source folders.  That<br/>\nworks smoothly enough.<br/>\n<br/>\n--Nat<br/>\n<br/>\n<blockquote><span title=\"qreply\"> On 26/07/07, Kent Beck &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:kentb@...\">kentb@...</a>&gt; wrote:<br/>\n&gt;<br/>\n&gt;   All,<br/>\n&gt;<br/>\n&gt; It seems clear to me that some sort of test classification scheme is a<br/>\n&gt; reasonable thing to add to JUnit. However, rather than simply copy one of<br/>\n&gt; the models out there we&#39;re going to go back to first principles and try to<br/>\n&gt; derive a model for classification that is concise, useful, flexible, and,<br/>\n&gt; above all, easy to use.<br/>\n&gt;<br/>\n&gt; I&#39;ve heard two purposes for classification:<br/>\n&gt; * Performance<br/>\n&gt; * Assumptions<br/>\n&gt;<br/>\n&gt; Performance<br/>\n&gt;<br/>\n&gt; If you have tests that run for longer than your attention span (my limits<br/>\n&gt; are 1 second for the inner loop of programming and 10 minutes for<br/>\n&gt; integration), running a subset of the tests can give you some assurance<br/>\n&gt; that<br/>\n&gt; the software is working. Classification is one way to reduce test run<br/>\n&gt; time--just this one test, all tests in this class, all tests in this<br/>\n&gt; package, all tests labeled &quot;quick&quot;, etc.<br/>\n&gt;<br/>\n&gt; There are other ways of reducing test run time. For example, you could<br/>\n&gt; have<br/>\n&gt; a runner that runs 1 second worth of the tests that have failed most<br/>\n&gt; recently or a runner that runs half a second of recently failed tests plus<br/>\n&gt; half a second of randomly selected tests.<br/>\n&gt;<br/>\n&gt; In the end I think the systemic solution to test run times is to improve<br/>\n&gt; design and testing techniques to dramatically increase the assurance/CPU<br/>\n&gt; cycle ratio.<br/>\n&gt;<br/>\n&gt; I remember a friend&#39;s story of an early project that used tests<br/>\n&gt; extensively.<br/>\n&gt; After three years they had a carefully tuned suite that took ten minutes<br/>\n&gt; to<br/>\n&gt; run. When the test runtime increased beyond ten minutes, they would work<br/>\n&gt; on<br/>\n&gt; the design of the system and/or the design of the tests to improve the<br/>\n&gt; assurance/CPU cycle ratio and get the runtime back under ten minutes. Then<br/>\n&gt; most of the original team left.<br/>\n&gt;<br/>\n&gt; A few years later my friend was shown the system. The programmer proudly<br/>\n&gt; explained that the test suites now took 24 hours to run, even though the<br/>\n&gt; system had grown little in functionality. They had stopped paying<br/>\n&gt; attention<br/>\n&gt; to designing for testability. Every time they added a new axis of<br/>\n&gt; variability they blindly ran the cross product of the existing tests with<br/>\n&gt; all the alternatives for the new axis. Yes they had more tests, but A/C<br/>\n&gt; had<br/>\n&gt; dropped by several orders of magnitude.<br/>\n&gt;<br/>\n&gt; In short, I see using classification to reduce test runtime as a bandage<br/>\n&gt; masking the real problem which is low A/C. Using classification to reduce<br/>\n&gt; test runtime really is a hack and I hope people will continue working to<br/>\n&gt; improve design for testability. We will still provide some classification<br/>\n&gt; mechanism, but that doesn&#39;t make it not a hack.<br/>\n&gt;<br/>\n&gt; Assumptions<br/>\n&gt;<br/>\n&gt; The second reason I&#39;ve heard for classification is to avoid a slew of<br/>\n&gt; misleadingly failing tests. If my development machine doesn&#39;t have access<br/>\n&gt; to<br/>\n&gt; the database, then if I run the database tests I&#39;ll get a bunch of<br/>\n&gt; failures<br/>\n&gt; even though the system is really working (or, to be more precise, I don&#39;t<br/>\n&gt; have any information about whether the system is really working or not).<br/>\n&gt;<br/>\n&gt; Classification is one way to express assumptions. When I say &quot;@Test(groups<br/>\n&gt; =<br/>\n&gt; {&quot;database&quot;})&quot; I have declared something about this test. However, this<br/>\n&gt; expression seems limited and error-prone to me. I&#39;d prefer to have the<br/>\n&gt; power<br/>\n&gt; of a programming language to express my assumptions.<br/>\n&gt;<br/>\n&gt; In the JUnit 4.4 you can use assumeThat() to express assumptions. For<br/>\n&gt; example, you can say:<br/>\n&gt;<br/>\n&gt; public class DatabaseTest {<br/>\n&gt; @BeforeClass public static void isDatabaseAccessible() {<br/>\n&gt; User result= Database.login(&quot;kent&quot;);<br/>\n&gt; assumeThat(not(isError(result));<br/>\n&gt; }<br/>\n&gt; ...<br/>\n&gt; }<br/>\n&gt;<br/>\n&gt; This is a bit of a workaround because runner don&#39;t yet handle failed<br/>\n&gt; assumptions as anything other than successful tests, but it gives you a<br/>\n&gt; richer language to express assumptions than a textual classification<br/>\n&gt; scheme.<br/>\n&gt;<br/>\n&gt; The Point<br/>\n&gt;<br/>\n&gt; So now the point of this long post. Are there other uses of classification<br/>\n&gt; that I&#39;ve missed? Is the above way of expressing assumptions (or something<br/>\n&gt; derived from it like an explicit @Assumption) sufficient?<br/>\n&gt;<br/>\n&gt; Regards,<br/>\n&gt;<br/>\n&gt; Kent Beck<br/>\n&gt; Three Rivers Institute<br/>\n&gt;<br/>\n&gt; [Non-text portions of this message have been removed]<br/>\n&gt;<br/>\n&gt;  <br/>\n&gt;<br/>\n<br/>\n<br/>\n[Non-text portions of this message have been removed] </span></blockquote></div>", 
    "prevInTime": 19686, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1186070264", 
    "canDelete": false, 
    "nextInTopic": 19692, 
    "prevInTopic": 19650, 
    "headers": {
        "inReplyToHeader": "PDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPg==", 
        "messageIdInHeader": "PDE3ZmE1M2QwNzA4MDIwODU3eTQ2NWQ1YjAycmRjMmM5NjYwNmRhNjgxZjZAbWFpbC5nbWFpbC5jb20+", 
        "referencesHeader": "PEFjZkp6WCtmVVR5WU9ZTXNUUG1VeEZ5MFRod29vUUJJblFsZ0FUbHF0c0E9PgkgPDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPg=="
    }
}