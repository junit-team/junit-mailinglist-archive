{
    "numMessagesInTopic": 48, 
    "nextInTime": 19651, 
    "senderId": "U74Cfbdziv5ZcPrFTTZ91KL0CzlyMcwR5uyPmUVp4jrJtS1kLu4WpCUlbF1fzrYFQJAZ5kCdPlhxDkBKqvPIzdGJPXE7", 
    "systemMessage": false, 
    "subject": "Re: [junit] Re: Test Grouping/Partitioning", 
    "from": "Paul King &lt;paulk@...&gt;", 
    "authorName": "Paul King", 
    "msgSnippet": "... For me classification gives me the ability to do appropriate slicing and dicing of my tests to: * maximize the information the tests can provide to me *", 
    "msgId": 19650, 
    "topicId": 19521, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 215576703, 
    "messageBody": "<div id=\"ygrps-yiv-1352930581\">Kent Beck wrote:<br/>\n<blockquote><span title=\"ireply\"> &gt; It seems clear to me that some sort of test classification scheme is a<br/>\n&gt; reasonable thing to add to JUnit. However, rather than simply copy one of<br/>\n&gt; the models out there we&#39;re going to go back to first principles and try to<br/>\n&gt; derive a model for classification that is concise, useful, flexible, and,<br/>\n&gt; above all, easy to use.<br/>\n&gt; <br/>\n&gt; I&#39;ve heard two purposes for classification:<br/>\n&gt; * Performance<br/>\n&gt; * Assumptions<br/>\n<br/>\n </span></blockquote>For me classification gives me the ability to do appropriate slicing<br/>\nand dicing of my tests to:<br/>\n* maximize the information the tests can provide to me<br/>\n* maximize my ability to manage risk in flexible ways<br/>\n<br/>\nIf I can slice my tests into unit, integration, acceptance etc and<br/>\ncheck what code coverage each return, that tells me a lot more than<br/>\njust an aggregate. A project with 100% coverage aggregate but with<br/>\n10% coverage coming from unit, and 10% from integration and the<br/>\nrest from acceptance will be vastly different from one that has<br/>\n100% from unit and none for the others and different too to one that<br/>\nhas 100% coverage for all three.<br/>\n<br/>\nAs an aside, I have seen large projects with 100% unit coverage and<br/>\n100% acceptance test coverage but never one with 100% integration <br/>\nlevel coverage - but you&#39;ll understand what I mean. Also, I used 100%<br/>\ncoverage in the above example but that was just an example - I don&#39;t<br/>\nadvocate 100% line or branch coverage as a magical metric we should<br/>\nnecessarily be striving for above all else.<br/>\n<br/>\nI can do some classification with naming conventions but having arbitrary<br/>\ngroups provides more flexibility. I don&#39;t think you need to go over<br/>\nboard here though, I don&#39;t need really fined grained flexibility here.<br/>\nIf you want that you are better off looking at what Clover 2 or Agitar<br/>\ndashboard do by bringing other measures of risk into the picture.<br/>\n<br/>\nThe same applies for CI systems. If I can slice and dice my tests, then<br/>\nI can better manage risk. I may run all my fast tests and a selection<br/>\nof very targeted acceptance and integration tests on every check in.<br/>\nI may run a broader set of tests for high-risk areas several times a day.<br/>\nI may run a complete regression suite nightly.<br/>\n<br/>\nI don&#39;t see having the ability to slice and dice the test suites in<br/>\nflexible ways as a hack but as a management tool that allows me to weigh<br/>\nup fast feedback cycles vs risk vs available hardware resources.<br/>\n<br/>\nCheers, Paul.</div>", 
    "prevInTime": 19649, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1185799294", 
    "canDelete": false, 
    "nextInTopic": 19687, 
    "prevInTopic": 19639, 
    "headers": {
        "inReplyToHeader": "PDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPg==", 
        "messageIdInHeader": "PDQ2QUREQzdFLjcwNjAxMDNAYXNlcnQuY29tLmF1Pg==", 
        "referencesHeader": "PDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPg=="
    }
}