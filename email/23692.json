{
    "numMessagesInTopic": 9, 
    "nextInTime": 23693, 
    "senderId": "or3MGQwpVTb0B1o7JZhhNnn542o2M_bwdV9U1YytqblOHiaiWY_FqIXYpjvV0Wlyy1vY140dLyvofIbfVwmF8SPz", 
    "systemMessage": false, 
    "subject": "Re: [junit] Re: Result and testAssumptionFailure handling", 
    "from": "David Saff &lt;david@...&gt;", 
    "authorName": "David Saff", 
    "msgSnippet": "OK, All of this has convinced me that we have a fairly well-understood set of three statuses, and there s a definite drop-off in usefulness-per-unit-complexity", 
    "msgId": 23692, 
    "profile": "dsaff", 
    "topicId": 23663, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 341876227, 
    "messageBody": "<div id=\"ygrps-yiv-947246084\">OK,<br/>\n<br/>\nAll of this has convinced me that we have a fairly well-understood set<br/>\nof three statuses, and there&#39;s a definite drop-off in<br/>\nusefulness-per-unit-complexity beyond that.  So, back to the original<br/>\nquestion, Stefan: yes, I think we should increase the ignored tests<br/>\ncount for an assumption failure.<br/>\n<br/>\nAnd Stephan, I&#39;m definitely glad you&#39;ve found it useful to implement<br/>\ndifferent Theory semantics in a different Runner; I don&#39;t think<br/>\nthere&#39;s a strong right-or-wrong about how to handle that particular<br/>\ncase.<br/>\n<br/>\n   David<br/>\n<br/>\n<blockquote><span title=\"qreply\"> On Thu, Sep 22, 2011 at 2:39 AM, sschroev &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:stephan202@...\">stephan202@...</a>&gt; wrote:<br/>\n&gt; Perhaps of interest is that we (the QA devs where I work) use a custom runner that slightly alters this behavior of Theories: if all of a Theory&#39;s assumptions fail, then we mark the test as skipped (as opposed to failed). This brings the semantics of the assume*() methods in the context of a @Test&#39;s and @Theory&#39;s much closer.<br/>\n&gt;<br/>\n&gt; (Background: this custom runner is used in a Selenium/WebDriver setup that is meant to test the UI of a system, irrespective of the system&#39;s underlying config/database. As such it is not uncommon that no suitable PotentialAssignments can be found for a given test setup. Yes, I am aware that this kind of test is anything but a unit test, but JUnit serves us very well regardless.)<br/>\n&gt;<br/>\n&gt; Stephan<br/>\n&gt;<br/>\n&gt; --- In <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a>, David Saff &lt;david@...&gt; wrote:<br/>\n&gt;&gt;<br/>\n&gt;&gt; So, it would be up to individual runners to figure out how to fit into<br/>\n&gt;&gt; the overall scheme.  Right now, the Theories runner doesn&#39;t report up<br/>\n&gt;&gt; individual assumption failures.  If every single data point results in<br/>\n&gt;&gt; an assumption failure, then the test is marked as failing.  If at<br/>\n&gt;&gt; least one data point fails, the test is marked as failing.  If at<br/>\n&gt;&gt; least one data point succeeds, and none fail, it&#39;s marked passing.<br/>\n&gt;&gt;<br/>\n&gt;&gt;     David<br/>\n&gt;&gt;<br/>\n&gt;&gt; On Mon, Sep 19, 2011 at 4:23 PM, Stephen Connolly<br/>\n&gt;&gt; &lt;stephen.alan.connolly@...&gt; wrote:<br/>\n&gt;&gt; &gt; I think there are a number of issues with this categorization... I<br/>\n&gt;&gt; &gt; think 4 might not be enough.<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; Here is my straw-man<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; Where do the<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; @Theory<br/>\n&gt;&gt; &gt; public void something() {<br/>\n&gt;&gt; &gt;  assumeThat(x, isLessThan(y))<br/>\n&gt;&gt; &gt;  ...<br/>\n&gt;&gt; &gt; }<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; assumption failure&#39;s get counted?<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; and how do you differentiate them from regular assumption failures?<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; -Stephen<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; On 19 September 2011 20:26, David Saff &lt;david@...&gt; wrote:<br/>\n&gt;&gt; &gt;&gt; Works for me, however...<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; It&#39;s also been proposed (I think as an analogy to NUnit, and maybe<br/>\n&gt;&gt; &gt;&gt; TestNG) that there should be four categories of test reports:<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; - PASSED<br/>\n&gt;&gt; &gt;&gt; - FAILED<br/>\n&gt;&gt; &gt;&gt; - IGNORED: The user asked the framework not to run this test.<br/>\n&gt;&gt; &gt;&gt; - ABORTED: The user asked the framework to run this test, but the<br/>\n&gt;&gt; &gt;&gt; framework couldn&#39;t.<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; The difference between IGNORED and ABORTED would be that the user<br/>\n&gt;&gt; &gt;&gt; shouldn&#39;t be surprised by IGNORED tests (the user took an action, like<br/>\n&gt;&gt; &gt;&gt; adding an @Ignore annotation, that caused the framework to skip the<br/>\n&gt;&gt; &gt;&gt; test).  However, an ABORTED test might be a surprise to the user: the<br/>\n&gt;&gt; &gt;&gt; test assumes that it is connected to the network, and that assumption<br/>\n&gt;&gt; &gt;&gt; failed.<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; Splitting out these states might allow tools depending on the test<br/>\n&gt;&gt; &gt;&gt; runs to take different actions based on the different results.  For<br/>\n&gt;&gt; &gt;&gt; example, ABORTED tests might be treated similarly to IGNORED tests<br/>\n&gt;&gt; &gt;&gt; during development, but would prevent check-in or deployment.<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; This raises three very different questions:<br/>\n&gt;&gt; &gt;&gt; (1) Should we have these 4 states, or stick with our current 3?<br/>\n&gt;&gt; &gt;&gt; (2) If we choose to have 4 states, what&#39;s the best name for the new state?<br/>\n&gt;&gt; &gt;&gt; (3) Are assumption failures, by default, to be treated as IGNORED, or ABORTED?<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; It might be good to get these decisions made, and move on.<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt;   David Saff<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; On Sun, Sep 18, 2011 at 8:10 PM, Stefan Birkner &lt;mail@...&gt; wrote:<br/>\n&gt;&gt; &gt;&gt;&gt; Currently the Result class simply ignores testAssumptionFailure. The corresponding method is empty and there&#39;s a comment: // do nothing: same as passing (for 4.5; may change in 4.6)<br/>\n&gt;&gt; &gt;&gt;&gt; I would like to increase the ignored tests count for an assumption failure. It&#39;s because Result doesn&#39;t provide any information, that a test is ignored because of a failing assumption.<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt; Any objections?<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt; ------------------------------------<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt; Yahoo! Groups Links<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;&gt;<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; ------------------------------------<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt; Yahoo! Groups Links<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;&gt;<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; ------------------------------------<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt; Yahoo! Groups Links<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt; &gt;<br/>\n&gt;&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; ------------------------------------<br/>\n&gt;<br/>\n&gt; Yahoo! Groups Links<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; </span></blockquote></div>", 
    "prevInTime": 23691, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1316698598", 
    "canDelete": false, 
    "nextInTopic": 0, 
    "prevInTopic": 23690, 
    "headers": {
        "inReplyToHeader": "PGo1ZWw3Myt2NXE2QGVHcm91cHMuY29tPg==", 
        "messageIdInHeader": "PENBQ2o4QnVQOHVIWGkrNjJzZVhYaW1Cd1BCcHFpc0oycDBRdTNROVoyRW5EYndYSkU2UUBtYWlsLmdtYWlsLmNvbT4=", 
        "referencesHeader": "PENBQ2o4QnVOSjU2ano2R05kRlJMT2l3V0NkUkstaVVqZnJOYzhqVGNORndGbVBVbU1GZ0BtYWlsLmdtYWlsLmNvbT4JPGo1ZWw3Myt2NXE2QGVHcm91cHMuY29tPg=="
    }
}