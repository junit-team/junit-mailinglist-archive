{
    "numMessagesInTopic": 4, 
    "nextInTime": 7271, 
    "senderId": "aJ7IpHDB82goclRsOWtIyupasPEMMAzKyGnI_i6mwIaZc1R-0IjfSsn-ga9fMRB-3Z1a651uO_RGwq04YIZKDi6zNQ", 
    "systemMessage": false, 
    "subject": "Re: [junit] Is a regression testing framework available?", 
    "from": "Bill Venners &lt;bv@...&gt;", 
    "authorName": "Bill Venners", 
    "msgSnippet": "Daniel, ... Yes, Vladimir and I did talk about this last week over turkey burgers. We spent most of the lunch comparing Vladimir s JUnit Add-Ons with ", 
    "msgId": 7270, 
    "rawEmail": "Return-Path: &lt;bv@...&gt;\r\nReceived: (qmail 81503 invoked by uid 7800); 20 Mar 2003 00:34:22 -0000\r\nX-Sender: bv@...\r\nX-Apparently-To: junit@yahoogroups.com\r\nReceived: (EGP: mail-8_2_6_5); 19 Mar 2003 17:32:35 -0000\r\nReceived: (qmail 7749 invoked from network); 19 Mar 2003 17:32:35 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m7.grp.scd.yahoo.com with QMQP; 19 Mar 2003 17:32:35 -0000\r\nReceived: from unknown (HELO artima1.inetu.net) (209.235.192.96)\n  by mta1.grp.scd.yahoo.com with SMTP; 19 Mar 2003 17:32:34 -0000\r\nReceived: (qmail 6557 invoked by uid 82); 19 Mar 2003 18:31:34 -0000\r\nReceived: from adsl-67-120-208-213.dsl.sntc01.pacbell.net (HELO artima.com) (67.120.208.213)\n  by res.artima1.inetu.net with SMTP; 19 Mar 2003 18:31:34 -0000\r\nDate: Wed, 19 Mar 2003 09:33:06 -0800\r\nSubject: Re: [junit] Is a regression testing framework available?\r\nContent-Type: text/plain; charset=US-ASCII; format=flowed\r\nMime-Version: 1.0 (Apple Message framework v551)\r\nTo: junit@yahoogroups.com\r\nContent-Transfer-Encoding: 7bit\r\nIn-Reply-To: &lt;1048093016.3e78a1580ce2c@...&gt;\r\nMessage-Id: &lt;D84AAF0C-5A30-11D7-99D8-00039301D446@...&gt;\r\nX-Mailer: Apple Mail (2.551)\r\nFrom: Bill Venners &lt;bv@...&gt;\r\nX-Yahoo-Group-Post: member; u=5637428\r\nX-Yahoo-Profile: billvenners\r\nX-eGroups-Approved-By: nails762 &lt;jbrains@...&gt; via email; 20 Mar 2003 00:34:22 -0000\r\n\r\nDaniel,\n\nOn Wednesday, March 19, 2003, at 08:56 AM, Vladimir R. Bossicard wrote:\n\n&gt;&gt; I would like to be able to find out which tests that have stopped\n&gt;&gt; working between two of our nightly builds (which run a set of JUnit\n&gt;&gt; tests). Since we currently have more than 500 test cases it is\n&gt;&gt; difficult to do this manually. It would of course be easy if the\n&gt;&gt; normal success rate was 100%, but a number of test cases fail since\n&gt;&gt; the implementation is not yet completed.\n&gt;\n&gt; Funny I discussed that with Bill Venners a few days ago.\n&gt;\nYes, Vladimir and I did talk about this last week over turkey burgers. \nWe spent most of the lunch comparing Vladimir&#39;s JUnit Add-Ons with \nSuiteRunner. It turns out we were both trying to address many of the \nsame issues when we built our respective JUnit extensions.\n\n&gt; Your problem is that not all of your tests pass.  So my question is: \n&gt; how can a\n&gt; developer be sure that he didn&#39;t introduce a bug with some new code?  \n&gt; X tests\n&gt; were failing before the modification and now Y tests are failing.  If \n&gt; Y&gt;X you\n&gt; don&#39;t know which one is/are now failing.\n&gt;\n&gt; IMO opinion (and in your case) you have two kinds of failing tests:\n&gt; - the one that shouldn&#39;t\n&gt; - the one that will, and it&#39;s ok (testing not implemented features, not\n&gt; implemented tests)\n&gt;\n&gt; JUnit doesn&#39;t directly give you the possibility to separate the &quot;good&quot; \n&gt; from the\n&gt; &quot;bad&quot; failing tests.  You have to come up with your own solution.\n&gt;\n&gt; What I would do:\n&gt; - rename the tests that should fail testXYZ_failing\n&gt; - rewrite some JUnit components (it depends what kind of runner you&#39;re \n&gt; using\n&gt; (ant, swing, textui) to filter these tests\n&gt; - or write an XSLT file to process the XML and remove the &#39;_failing&#39; \n&gt; methods\n&gt; from the report\n&gt;\nI had never imagined this kind of problem before talking to Vladimir, \nbut this morning I realized that it sounds like a good candidate for a \ncustom reporter. If you use SuiteRunner as your JUnit runner, you can \ncreate a custom reporter that I think will solve your problem. This \nreporter should:\n\n1. Record persistently (in a database or file, for example) the tests \nthat fail.\n2. Open up the persistent record of failed tests from the previous run, \ncompare that with the current set of failed tests, and indicate the \ndifferences to the user.\n\nA couple weeks ago I published an article about how to create a custom \nreporter that should get you started:\n\nhttp://www.artima.com/suiterunner/xmlreporter.html\n\nIf you run into trouble, please post to the SuiteRunner forum and we&#39;ll \ntry and help:\n\nhttp://www.artima.com/forums/forum.jsp?forum=61\n\nBill\n--\nBill Venners\nArtima Software, Inc.\nhttp://www.artima.com\n\n\n", 
    "profile": "billvenners", 
    "topicId": 7256, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 5637428, 
    "prevInTime": 7269, 
    "contentTrasformed": false, 
    "postDate": "1048095186", 
    "canDelete": false, 
    "nextInTopic": 7365, 
    "prevInTopic": 7264, 
    "headers": {
        "inReplyToHeader": "PDEwNDgwOTMwMTYuM2U3OGExNTgwY2UyY0BtYWlsLnNjZGkub3JnPg==", 
        "messageIdInHeader": "PEQ4NEFBRjBDLTVBMzAtMTFENy05OUQ4LTAwMDM5MzAxRDQ0NkBhcnRpbWEuY29tPg=="
    }
}