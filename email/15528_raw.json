{
    "numMessagesInTopic": 11, 
    "nextInTime": 15529, 
    "senderId": "TVn56ow4m2-IVMLZHPWuhSmnYh0Dnkx7AXXEHsAPB17T_uI95ZFSc5R8YulKPqjx0ykrh8yJh9oqOgQ_tlQt0ETCCIvj7V-UfGtIeEbmjA", 
    "systemMessage": false, 
    "subject": "Re: [junit] Re: Categories in JUnit4?", 
    "from": "&quot;J. B. Rainsberger&quot; &lt;jbrains@...&gt;", 
    "authorName": "J. B. Rainsberger", 
    "msgSnippet": "... Yes, although I did it with tag interfaces, rather than with annotations. I then had test case filters that collects all tests that implemented a given", 
    "msgId": 15528, 
    "rawEmail": "Return-Path: &lt;jbrains@...&gt;\r\nX-Sender: jbrains@...\r\nX-Apparently-To: junit@yahoogroups.com\r\nReceived: (qmail 89653 invoked from network); 28 Nov 2005 03:50:11 -0000\r\nReceived: from unknown (66.218.66.217)\n  by m31.grp.scd.yahoo.com with QMQP; 28 Nov 2005 03:50:11 -0000\r\nReceived: from unknown (HELO smtp105.rog.mail.re2.yahoo.com) (206.190.36.83)\n  by mta2.grp.scd.yahoo.com with SMTP; 28 Nov 2005 03:50:11 -0000\r\nReceived: (qmail 97267 invoked from network); 28 Nov 2005 03:49:57 -0000\r\nReceived: from unknown (HELO ?10.6.114.105?) (srainsberger5790@...@67.151.13.130 with plain)\n  by smtp105.rog.mail.re2.yahoo.com with SMTP; 28 Nov 2005 03:49:57 -0000\r\nMessage-ID: &lt;438A4DB7.2050106@...&gt;\r\nDate: Sun, 27 Nov 2005 19:22:15 -0500\r\nUser-Agent: Thunderbird 1.5 (Macintosh/20051025)\r\nMIME-Version: 1.0\r\nTo: junit@yahoogroups.com\r\nReferences: &lt;dm7qta+fkhb@...&gt;\r\nIn-Reply-To: &lt;dm7qta+fkhb@...&gt;\r\nContent-Type: text/plain; charset=ISO-8859-1; format=flowed\r\nContent-Transfer-Encoding: 7bit\r\nX-eGroups-Msg-Info: 1:12:0:0\r\nFrom: &quot;J. B. Rainsberger&quot; &lt;jbrains@...&gt;\r\nSubject: Re: [junit] Re: Categories in JUnit4?\r\nX-Yahoo-Group-Post: member; u=127224993; y=8b10FPUOsR1aA6BPFwmSy526hqLgMuMvl9DP_DM2qO4kb-c\r\nX-Yahoo-Profile: nails762\r\n\r\nJon Skeet wrote:\n&gt; --- In junit@yahoogroups.com, &quot;J. B. Rainsberger&quot; &lt;jbrains@r...&gt; wrote:\n&gt;  &gt; &gt; So, why am I wrong? :)\n&gt;  &gt;\n&gt;  &gt; You&#39;re not wrong, but I do something differently, and prefer it.\n&gt; \n&gt; Does that mean you&#39;ve tried the annotation way of working for a\n&gt; significant amount of time?\n\nYes, although I did it with tag interfaces, rather than with \nannotations. I then had test case filters that collects all tests that \nimplemented a given interface, like DatabaseTest, AcceptanceTest, \nPerformanceTest, and so on. After about 3 months, I noticed that I \nwasn&#39;t running the &quot;Database&quot; tests, and that only a handful of test \ncase classes implemented more than one interface. I also noticed that I \nwas running all the tests most of the time, anyway.\n&gt; \n&gt;  &gt; Tests sometimes naturally divide themselves along the axis of &quot;how\n&gt;  &gt; often we run them&quot;.\n&gt; \n&gt; That&#39;s certainly *one* aspect of how they divide themselves. However,\n&gt; there&#39;s more than that.\n&gt; \n&gt; &lt;snip&gt;\n&gt; \n&gt; I separate production source from test source, but currently all our\n&gt; test cases are in one tree (per project).\n&gt; \n&gt; The main problem I see with your solution (other than it not keeping\n&gt; all the tests for one class in a single easily findable place) is that\n&gt; it only works while you&#39;ve only got one axis you want to divide the\n&gt; tests up by. Another axis which is relevant for us is which area of\n&gt; functionality is involved - and that may not always be feasible on a\n&gt; package/namespace basis. For instance, if all db-schema-sensitive\n&gt; tests are categorised as such, then after making a schema change I can\n&gt; run all those tests, whether they&#39;re also performance tests or not.\n\nWhy can&#39;t you run all the /unit/ tests before a check-in? Don&#39;t they \nmostly all run in memory, anyway?\n\nAlso, since database-related tests are usually slower than tests that \nrun entirely in memory, is there /really/ a big difference in execution \ntime between running all the database-related tests and running /all/ \nthe tests. In my experience, the difference is usually measured in tens \nof seconds, and not tens of minutes. After all, 1000 in-memory tests \nusually run in 10-30 seconds. What&#39;s 10-30 seconds more, compared to a \ntest run that takes 20-30 minutes? For that matter, what&#39;s 1-2 minutes \nmore? Why not just run all the tests, rather than spend the extra time \ncategorizing them just so?\n\n &gt; In\n &gt; the situation where running *all* unit tests just isn&#39;t feasible\n &gt; before every check-in, being easily able to choose which tests are run\n &gt; (across both NUnit and JUnit, by the way) to verify that nothing&#39;s\n &gt; been broken requires more flexibility than a single axis would\n &gt; provide.\n\nIn a configuration that complex, I would probably not have enough \nconfidence to ship code without running every single test. If the system \nis really that big, and test runs take hours, then I would immediately \nevaluate the benefits of splitting that system into loosely coupled \nparts and evolving them in separate source trees. My hunch is that the \nresult would be easier to manage and would have much faster tests, on \nthe whole.\n\nDo bear in mind how much I&#39;m speculating. It&#39;s possible that you&#39;ve \nalready considered all this and rejected it; but I&#39;ve simply never found \nmyself in such a situation, so I&#39;m imagining how I would deal with that \nsituation if I found myself in it.\n-- \nJ. B. (Joe) Rainsberger :: http://www.jbrains.info\nYour guide to software craftsmanship\nJUnit Recipes: Practical Methods for Programmer Testing\n2005 Gordon Pask Award for contribution Agile Software Practice\n\n\n", 
    "profile": "nails762", 
    "topicId": 15505, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 127224993, 
    "prevInTime": 15527, 
    "contentTrasformed": false, 
    "postDate": "1133137335", 
    "canDelete": false, 
    "nextInTopic": 15531, 
    "prevInTopic": 15525, 
    "headers": {
        "inReplyToHeader": "PGRtN3F0YStma2hiQGVHcm91cHMuY29tPg==", 
        "messageIdInHeader": "PDQzOEE0REI3LjIwNTAxMDZAcm9nZXJzLmNvbT4=", 
        "referencesHeader": "PGRtN3F0YStma2hiQGVHcm91cHMuY29tPg=="
    }
}