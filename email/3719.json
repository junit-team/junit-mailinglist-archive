{
    "numMessagesInTopic": 1, 
    "nextInTime": 3720, 
    "senderId": "Gc_eUhZ3al5UnR375qqfuQDnhB2sq_48cE1Gpo3KxLURoE_GzFYng5Ab0Tm8EV22FQ7-xVLPP_h7rBTvIqsLPfOfTE-Sub1Dlxk", 
    "systemMessage": false, 
    "subject": "Re: [junit]", 
    "from": "&quot;David Stagner&quot; &lt;dstagner@...&gt;", 
    "authorName": "David Stagner", 
    "msgSnippet": "... This sounds like an acceptance test problem to me, not a unit test problem (read or re-read the various XP books on the subject).  In order to generate", 
    "msgId": 3719, 
    "profile": "d_stagner", 
    "topicId": 3719, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 75470680, 
    "messageBody": "<div id=\"ygrps-yiv-1879030438\">David V. Olivier wrote:<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; I use JUnit for about 90% of my code.  I would like to use it for 100% but <br/>\n&gt; I consistently find automated testing of certain types of functionality <br/>\n&gt; particular difficult to accomplish.  My work is in digital mapping, and I <br/>\n&gt; find complex operations on large data sets problematic.<br/>\n&gt; <br/>\n&gt; Let me give a specific example:<br/>\n&gt; <br/>\n&gt; I am currently implementing functionality to warp satellite images from one <br/>\n&gt; mapping projection to another.  The image is distorted according to a <br/>\n&gt; complex formula.  On a low level, I can test that for a given input my <br/>\n&gt; implementation of the formula provides the result I expect, but on a higher <br/>\n&gt; level I haven&#39;t been able to automate verification of that the final image <br/>\n&gt; is correct.  I have only been able to superimpose the result on a <br/>\n&gt; background map I know is correct and eyeball the results.<br/>\n<br/>\n </span></blockquote>This sounds like an acceptance test problem to me, not a unit test <br/>\nproblem (read or re-read the various XP books on the subject).  In order <br/>\nto generate this complex map, you&#39;re iteratively processing data, right? <br/>\n  Well, unit test the processing functions to make sure that they&#39;re <br/>\ngenerating correct numbers in the simplest cases.  That should already <br/>\nbe unit-testable (and it sounds like you&#39;re already on the right track <br/>\nthere).  Now, for the large-scale results, write an acceptance test <br/>\nfeeding a known good dataset in, save the output as a file (the image is <br/>\na file, right?), and bitwise-compare it to a known good output.  I&#39;m <br/>\npresuming your model is deterministic and identical inputs always <br/>\nproduce identical outputs.  An MD5 checksum can check for you at roughly <br/>\nthe speed of disk access for the file.  Script it!<br/>\n<br/>\nBasically, it sounds hard to unit test because it isn&#39;t a unit test <br/>\nproblem.  Treat it on the proper level and it should be much easier. <br/>\n(Note that this approach doesn&#39;t always work... some years ago, i was a <br/>\nbuild engineer for a cross-platform ERP system.  I wrote a neat little <br/>\nscript to diff the 600+ compiled binaries so i knew what changed from <br/>\none build to the next.  Worked great on Unix.  But on Windows, the <br/>\ncompiler embedded a timestamp in the binary, so no two binaries were <br/>\never bitwise-identical.  Sigh.)<br/>\n<br/>\n-- <br/>\n<br/>\nDavid Stagner<br/>\n<br/>\nNational Marrow Donor Program<br/>\n3001 Broadway Street NE<br/>\nBroadway Ridge Suite 500<br/>\nMinneapolis, MN  55413<br/>\n<br/>\nEmail: <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:dstagner@...\">dstagner@...</a></div>", 
    "prevInTime": 3718, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1010591266", 
    "canDelete": false, 
    "nextInTopic": 0, 
    "prevInTopic": 0, 
    "headers": {
        "messageIdInHeader": "PDNDM0M2NjIyLjUwMjA3MDJAbm1kcC5vcmc+", 
        "referencesHeader": "PDUuMS4wLjE0LjIuMjAwMjAxMDkwOTE2MTcuMDBhZjFkMDhAY3lwcmVzcy5ucmxzc2MubmF2eS5taWw+"
    }
}