{
    "numMessagesInTopic": 3, 
    "nextInTime": 6636, 
    "senderId": "PSFF2m6_QRNYdfEQbouzD0KV8gGNszp1f5rqw-al4pPwdUpzj8967YOOXyzZsIebZHAeR21DBMA77kvW6oiikQYGhh6ArP21", 
    "systemMessage": false, 
    "subject": "Re: [junit] How to count test assertions", 
    "from": "Shane Celis &lt;shane.celis@...&gt;", 
    "authorName": "Shane Celis", 
    "msgSnippet": "This is likely to stir up some debate, because many tests can be written that don t require any asserts.  So a test shouldn t be judged by the number of", 
    "msgId": 6635, 
    "topicId": 6634, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 132411217, 
    "messageBody": "<div id=\"ygrps-yiv-1191451339\">This is likely to stir up some debate, because many tests can be <br/>\nwritten that don&#39;t require any asserts.  So a test shouldn&#39;t be judged <br/>\nby the number of asserts it uses.  (However, I have been in situations <br/>\nwhere I did flush out a test by adding more asserts and the fact that <br/>\nthe output looked no different was somewhat disappointing.)<br/>\n<br/>\nI&#39;m tempted to say that the generated tests is what you should look <br/>\ninto, rather than JUnit.  For example, if your generated test put <br/>\nsomething like this into the body:<br/>\n<br/>\nthrow new Exception(&quot;Test Not Yet Implemented&quot;);<br/>\n<br/>\nThen you would have a complete TODO list of all the methods you&#39;ve left <br/>\nto write tests for and wouldn&#39;t be receiving these false positives.  <br/>\nBut having a ton of errors coming from your tests isn&#39;t a great <br/>\nsolution either.  It would be nice if JUnit provided a means for test <br/>\ngenerators to inform JUnit like so:<br/>\n<br/>\nAuto generated tests might look like:<br/>\n<br/>\nvoid testFoo() {<br/>\n\tthrow new NotYetImplementedException();<br/>\n}<br/>\n<br/>\nOutput might look like:<br/>\n<br/>\n.......F<br/>\n[/snip]<br/>\nFAILURES!!!<br/>\nTests run: 8,  Failures: 1,  Errors: 0,  NYI: 302<br/>\n<br/>\n-shane<br/>\n<br/>\n<br/>\nOn Thursday, January 9, 2003, at 12:51  PM, SteveKelem <br/>\n&lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:s_kelem@...\">s_kelem@...</a>&gt; wrote:<br/>\n<br/>\n<blockquote><span title=\"qreply\"> &gt; JUnit (3.8.1) counts the number of test methods that pass/fail.<br/>\n&gt; With some of the test generation methods, such as JUnitDoclet, empty<br/>\n&gt; methods are generated (a good thing) for each class. But when the<br/>\n&gt; tests are run, the generated document shows that all these methods<br/>\n&gt; pass (questionably good).  This gives a false sense that the code<br/>\n&gt; being tested is being tested, when it really isn&#39;t because the test<br/>\n&gt; bodies are empty.<br/>\n&gt;<br/>\n&gt; Is there a way to track the number of assertions that pass/fail<br/>\n&gt; instead of the number of methods that are invoked in the test classes?<br/>\n&gt;  This way the numbers reported (e.g., 122 tests run) would tend to<br/>\n&gt; imply better test coverage, or at least more actual tests executing,<br/>\n&gt; rather than lots of empty tests running.  (Yes, I know bad tests can<br/>\n&gt; be written that skew the results, but we don&#39;t need to go into that<br/>\n&gt; now.)<br/>\n&gt; This way more the classes for which tests haven&#39;t yet been written,<br/>\n&gt; but the skeleton is up and running, would show up in the report as 0<br/>\n&gt; tests run, rather than whatever number of test skeletons have been<br/>\n&gt; generated<br/>\n&gt; and may or may not be empty.<br/>\n&gt;<br/>\n&gt; Thanks,<br/>\n&gt; Steve Kelem </span></blockquote></div>", 
    "prevInTime": 6634, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1042161582", 
    "canDelete": false, 
    "nextInTopic": 6638, 
    "prevInTopic": 6634, 
    "headers": {
        "inReplyToHeader": "PGF2a25jYitwYW5kQGVHcm91cHMuY29tPg==", 
        "messageIdInHeader": "PDk4RjhCOTE2LTI0MzktMTFENy04QzM2LTAwMzA2NUY5QTgwRUBzdW4uY29tPg=="
    }
}