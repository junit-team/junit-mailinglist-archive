{
    "numMessagesInTopic": 1, 
    "nextInTime": 11331, 
    "senderId": "sgg9L4bDt9SiatSsuBR8ONENdU1eJuDa_DC8Hh5S-6-Lqf4DZyt9agjs-5fbLynKf9qjy1QjVHNvmT2d1UzT8g", 
    "systemMessage": false, 
    "subject": "FW: [junit] Comparing consecutive results? xslt sheet?", 
    "from": "&quot;Morten Grum&quot; &lt;mg@...&gt;", 
    "authorName": "Morten Grum", 
    "msgSnippet": "Hi Brett Well we do aim at having all tests pass all the time and we do though away meaningless tests that don t correspond to the current situation. But the", 
    "msgId": 11330, 
    "profile": "morten3grum", 
    "topicId": 11330, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 11862826, 
    "messageBody": "<div id=\"ygrps-yiv-1643502758\">Hi Brett<br/>\n<br/>\nWell we do aim at having all tests pass all the time and we do though away<br/>\nmeaningless tests that don&#39;t correspond to the current situation. <br/>\n<br/>\nBut the software is in use for real world engineering consultancy all the<br/>\ntime (sometimes by us the developers) and priorities are often set by acute<br/>\nneeds of the users. Sometimes we have a few hours from a new requirement to<br/>\nits corresponding new release and use on a consultancy project. In such a<br/>\nsituation we cannot avoid having tests (both unit and acceptance tests) that<br/>\ndon&#39;t pass but that should be brought to passing soon. Functionality that<br/>\nbreaks but that should soon be bought to work again (not that the test is<br/>\nout of date but that the functionality is broken). But I do agree that the<br/>\naim is always to have all tests passing and unit tests that stay failing for<br/>\nlong could have a tendency to make failing tests an &quot;acceptable thing&quot;.<br/>\n<br/>\n<blockquote><span title=\"ireply\"> &gt; Did that answer help at all?<br/>\n </span></blockquote>I&#39;m always open to a good discussion on best practice (especially after<br/>\nhaving adopted several tips from this list and other agile tips).<br/>\n<br/>\nHowever, at the moment we manually compare two junit-report html outputs<br/>\nfrom before and after some change (and relative to this or that version).<br/>\nAnd then failing tests do really take a lot of time and are a problem. We<br/>\nwere wondering it we could track test creation-passing-failing-deletion in a<br/>\nbetter way (and place this in our nightly build). I thought it might be<br/>\npossible to generate a junit-report from two or more consecutive junit xml<br/>\nresult sets. Thought it might be a question of using another xslt file for<br/>\njunit-report or some other tool. ?<br/>\n<br/>\nThanks<br/>\nMorten<br/>\n<br/>\n<br/>\n<blockquote><span title=\"qreply\"> &gt; -----Original Message-----<br/>\n&gt; From: Brett Neumeier [mailto:<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:random@...\">random@...</a>]<br/>\n&gt; Sent: 01 July 2004 03:54<br/>\n&gt; To: <a rel=\"nofollow\" target=\"_blank\" href=\"mailto:junit@yahoogroups.com\">junit@yahoogroups.com</a><br/>\n&gt; Subject: Re: [junit] Comparing consecutive results? xslt sheet?<br/>\n&gt; <br/>\n&gt; On Wed, 2004-06-30 at 16:16, Morten Grum wrote:<br/>\n&gt; &gt; Is there a good way of comparing/tracking consecutive junit result sets?<br/>\n&gt; &gt; Perhaps with a xslt style sheet for junit-report?<br/>\n&gt; <br/>\n&gt; The best situation to be in is to have all the tests pass.  If you don&#39;t<br/>\n&gt; have all the tests passing, and you can&#39;t get them to pass in a<br/>\n&gt; relatively short timeframe, then you might want to ask yourself what the<br/>\n&gt; value of having the failing tests is.<br/>\n&gt; <br/>\n&gt; (I&#39;ve been on a team where some of the tests stayed broken for many<br/>\n&gt; weeks. I don&#39;t know why we kept those tests; it&#39;s not as though they<br/>\n&gt; added any confidence that the system worked properly.  At least, they<br/>\n&gt; didn&#39;t provide me with any of that sort of confidence; they mostly<br/>\n&gt; provided me with confidence that the tests weren&#39;t an accurate<br/>\n&gt; reflection of the state of the system.)<br/>\n&gt; <br/>\n&gt; If all the tests pass, the only value to compare from one run to the<br/>\n&gt; next is &quot;how many tests are there&quot; -- and that&#39;s not something that you<br/>\n&gt; really need a stylesheet to manage.<br/>\n&gt; <br/>\n&gt; Did that answer help at all?<br/>\n&gt; <br/>\n&gt; --<br/>\n&gt; Brett Neumeier &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:random@...\">random@...</a>&gt;<br/>\n&gt; <br/>\n&gt; <br/>\n&gt; <br/>\n&gt; <br/>\n&gt; Yahoo! Groups Links<br/>\n&gt; <br/>\n&gt; <br/>\n&gt; <br/>\n&gt; </span></blockquote></div>", 
    "prevInTime": 11329, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1088663097", 
    "canDelete": false, 
    "nextInTopic": 0, 
    "prevInTopic": 0, 
    "headers": {}
}