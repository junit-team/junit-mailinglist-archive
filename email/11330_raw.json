{
    "numMessagesInTopic": 1, 
    "nextInTime": 11331, 
    "senderId": "h_uVLpQJ7JuN1Ep9fKGS2rFkh9WzR3tpNmxSFPeeAgh6DWm38dFamX-wVXL0gfCMmSK5FlkUBfvHA7p5sQasRg", 
    "systemMessage": false, 
    "subject": "FW: [junit] Comparing consecutive results? xslt sheet?", 
    "from": "&quot;Morten Grum&quot; &lt;mg@...&gt;", 
    "authorName": "Morten Grum", 
    "msgSnippet": "Hi Brett Well we do aim at having all tests pass all the time and we do though away meaningless tests that don t correspond to the current situation. But the", 
    "msgId": 11330, 
    "rawEmail": "Return-Path: &lt;mg@...&gt;\r\nX-Sender: mg@...\r\nX-Apparently-To: junit@yahoogroups.com\r\nReceived: (qmail 22766 invoked from network); 1 Jul 2004 06:24:53 -0000\r\nReceived: from unknown (66.218.66.216)\n  by m13.grp.scd.yahoo.com with QMQP; 1 Jul 2004 06:24:53 -0000\r\nReceived: from unknown (HELO DHNSRV2.dalgashave.dk) (195.97.179.3)\n  by mta1.grp.scd.yahoo.com with SMTP; 1 Jul 2004 06:24:52 -0000\r\nReceived: from MGJUNI2004 ([212.130.99.237]) by DHNSRV2.dalgashave.dk with SMTP (Microsoft Exchange Internet Mail Service Version 5.5.2650.21)\n\tid N9Z9VRCT; Thu, 1 Jul 2004 08:24:26 +0200\r\nTo: &quot;JunitList&quot; &lt;junit@yahoogroups.com&gt;\r\nDate: Thu, 1 Jul 2004 08:24:57 +0200\r\nOrganization: Morten Grum, PH-Consult\r\nMIME-Version: 1.0\r\nContent-Type: text/plain;\n\tcharset=&quot;US-ASCII&quot;\r\nContent-Transfer-Encoding: 7bit\r\nX-Mailer: Microsoft Office Outlook, Build 11.0.5510\r\nX-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1106\r\nThread-Index: AcRfDlmP9NbWn+XSQR2PfzbF7vB9AgAIX85gAADkPFA=\r\nX-eGroups-Remote-IP: 195.97.179.3\r\nFrom: &quot;Morten Grum&quot; &lt;mg@...&gt;\r\nReply-To: &lt;mg@...&gt;\r\nSubject: FW: [junit] Comparing consecutive results? xslt sheet?\r\nX-Yahoo-Group-Post: member; u=11862826\r\nX-Yahoo-Profile: morten3grum\r\n\r\nHi Brett\n\nWell we do aim at having all tests pass all the time and we do though away\nmeaningless tests that don&#39;t correspond to the current situation. \n\nBut the software is in use for real world engineering consultancy all the\ntime (sometimes by us the developers) and priorities are often set by acute\nneeds of the users. Sometimes we have a few hours from a new requirement to\nits corresponding new release and use on a consultancy project. In such a\nsituation we cannot avoid having tests (both unit and acceptance tests) that\ndon&#39;t pass but that should be brought to passing soon. Functionality that\nbreaks but that should soon be bought to work again (not that the test is\nout of date but that the functionality is broken). But I do agree that the\naim is always to have all tests passing and unit tests that stay failing for\nlong could have a tendency to make failing tests an &quot;acceptable thing&quot;.\n\n&gt; Did that answer help at all?\nI&#39;m always open to a good discussion on best practice (especially after\nhaving adopted several tips from this list and other agile tips).\n\nHowever, at the moment we manually compare two junit-report html outputs\nfrom before and after some change (and relative to this or that version).\nAnd then failing tests do really take a lot of time and are a problem. We\nwere wondering it we could track test creation-passing-failing-deletion in a\nbetter way (and place this in our nightly build). I thought it might be\npossible to generate a junit-report from two or more consecutive junit xml\nresult sets. Thought it might be a question of using another xslt file for\njunit-report or some other tool. ?\n\nThanks\nMorten\n\n\n&gt; -----Original Message-----\n&gt; From: Brett Neumeier [mailto:random@...]\n&gt; Sent: 01 July 2004 03:54\n&gt; To: junit@yahoogroups.com\n&gt; Subject: Re: [junit] Comparing consecutive results? xslt sheet?\n&gt; \n&gt; On Wed, 2004-06-30 at 16:16, Morten Grum wrote:\n&gt; &gt; Is there a good way of comparing/tracking consecutive junit result sets?\n&gt; &gt; Perhaps with a xslt style sheet for junit-report?\n&gt; \n&gt; The best situation to be in is to have all the tests pass.  If you don&#39;t\n&gt; have all the tests passing, and you can&#39;t get them to pass in a\n&gt; relatively short timeframe, then you might want to ask yourself what the\n&gt; value of having the failing tests is.\n&gt; \n&gt; (I&#39;ve been on a team where some of the tests stayed broken for many\n&gt; weeks. I don&#39;t know why we kept those tests; it&#39;s not as though they\n&gt; added any confidence that the system worked properly.  At least, they\n&gt; didn&#39;t provide me with any of that sort of confidence; they mostly\n&gt; provided me with confidence that the tests weren&#39;t an accurate\n&gt; reflection of the state of the system.)\n&gt; \n&gt; If all the tests pass, the only value to compare from one run to the\n&gt; next is &quot;how many tests are there&quot; -- and that&#39;s not something that you\n&gt; really need a stylesheet to manage.\n&gt; \n&gt; Did that answer help at all?\n&gt; \n&gt; --\n&gt; Brett Neumeier &lt;random@...&gt;\n&gt; \n&gt; \n&gt; \n&gt; \n&gt; Yahoo! Groups Links\n&gt; \n&gt; \n&gt; \n&gt; \n\n\n", 
    "profile": "morten3grum", 
    "topicId": 11330, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 11862826, 
    "prevInTime": 11329, 
    "contentTrasformed": false, 
    "postDate": "1088663097", 
    "canDelete": false, 
    "nextInTopic": 0, 
    "prevInTopic": 0, 
    "headers": {}
}