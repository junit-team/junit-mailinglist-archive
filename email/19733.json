{
    "numMessagesInTopic": 48, 
    "nextInTime": 19734, 
    "senderId": "-Ac-T48dt3KkuLzIxH6Si3z2g4xp2UiGQoBNhVba8O52yzmjjAT_bdCuyNyoknsEt7bEJhcItbncPgKkAV-bHDFn", 
    "systemMessage": false, 
    "subject": "Re: [junit] Re: Test Grouping/Partitioning", 
    "from": "&quot;David Saff&quot; &lt;saff@...&gt;", 
    "authorName": "David Saff", 
    "msgSnippet": "Nat, Kevin Lawrence at Agitar has a great way of dealing with this that I like: http://www.developertesting.com/archives/month200608/20060811-FailingTests.html", 
    "msgId": 19733, 
    "profile": "dsaff", 
    "topicId": 19521, 
    "spamInfo": {
        "reason": "0", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 139771899, 
    "messageBody": "<div id=\"ygrps-yiv-986666980\">Nat,<br/>\n<br/>\nKevin Lawrence at Agitar has a great way of dealing with this that I like:<br/>\n<br/>\n<a rel=\"nofollow\" target=\"_blank\" href=\"http://www.developertesting.com/archives/month200608/20060811-FailingTests.html\">http://www.developertesting.com/archives/month200608/20060811-FailingTests.html</a><br/>\n<br/>\nThis was one of the inspirations behind the assumptions support in<br/>\nJUnit 4.4.  I imagine, but haven&#39;t yet written, a method bugFixed()<br/>\nsuch that I can write:<br/>\n<br/>\n@Test public void niftyNewCheckbox() {<br/>\n   assumeTrue(bugFixed(45678));<br/>\n   // test checkbox<br/>\n}<br/>\n<br/>\nIf your new features are not in bugzilla or some such thing, then you could say<br/>\n<br/>\n<br/>\n@Test public void niftyNewCheckbox() {<br/>\n   assumeTrue(versionAtLeast(4.5));<br/>\n   // test checkbox<br/>\n}<br/>\n<br/>\nIn general, I prefer that whatever category support we implement<br/>\nshould be primarily for running relatively small subsets of the tests.<br/>\n If I want to run all of the tests except a couple, I&#39;d rather state<br/>\nin those tests what my assumptions are that are currently invalid (not<br/>\nenough time, no user at the keyboard, feature not finished yet).<br/>\n<br/>\nThoughts?<br/>\n<br/>\n   David Saff<br/>\n<br/>\n<br/>\n<blockquote><span title=\"qreply\"> On 8/2/07, Nat Pryce &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:nat.pryce@...\">nat.pryce@...</a>&gt; wrote:<br/>\n&gt; I&#39;ve just thought of another categorisation of tests: whether they are<br/>\n&gt; regression tests or work in progress.<br/>\n&gt;<br/>\n&gt; We write tests for the functionality to be delivered in the upcoming<br/>\n&gt; iteration.  Those tests will initially fail.  As we go through the iteration<br/>\n&gt; more and more of them will pass as we complete the work.  However, we can&#39;t<br/>\n&gt; let the failing tests stop us checking in changes.  So we categorise tests<br/>\n&gt; as &quot;work-in-progress&quot; or &quot;regression&quot;.  Work-in-progress tests are allowed<br/>\n&gt; to fail without breaking the CI build.  A failing regression test breaks the<br/>\n&gt; build and must be fixed immediately before further changes can be checked<br/>\n&gt; in.<br/>\n&gt;<br/>\n&gt; At the end of the iteration, passing &quot;work-in-progress&quot; tests are<br/>\n&gt; recategorised as regression tests.If new work requires changes to existing<br/>\n&gt; functionality, the regression tests for that  functionality are<br/>\n&gt; recategorised as &quot;work-in-progress&quot; until the new work is done.<br/>\n&gt;<br/>\n&gt; At the moment we just move tests between different source folders.  That<br/>\n&gt; works smoothly enough.<br/>\n&gt;<br/>\n&gt; --Nat<br/>\n&gt;<br/>\n&gt; On 26/07/07, Kent Beck &lt;<a rel=\"nofollow\" target=\"_blank\" href=\"mailto:kentb@...\">kentb@...</a>&gt; wrote:<br/>\n&gt; &gt;<br/>\n&gt; &gt;   All,<br/>\n&gt; &gt;<br/>\n&gt; &gt; It seems clear to me that some sort of test classification scheme is a<br/>\n&gt; &gt; reasonable thing to add to JUnit. However, rather than simply copy one of<br/>\n&gt; &gt; the models out there we&#39;re going to go back to first principles and try to<br/>\n&gt; &gt; derive a model for classification that is concise, useful, flexible, and,<br/>\n&gt; &gt; above all, easy to use.<br/>\n&gt; &gt;<br/>\n&gt; &gt; I&#39;ve heard two purposes for classification:<br/>\n&gt; &gt; * Performance<br/>\n&gt; &gt; * Assumptions<br/>\n&gt; &gt;<br/>\n&gt; &gt; Performance<br/>\n&gt; &gt;<br/>\n&gt; &gt; If you have tests that run for longer than your attention span (my limits<br/>\n&gt; &gt; are 1 second for the inner loop of programming and 10 minutes for<br/>\n&gt; &gt; integration), running a subset of the tests can give you some assurance<br/>\n&gt; &gt; that<br/>\n&gt; &gt; the software is working. Classification is one way to reduce test run<br/>\n&gt; &gt; time--just this one test, all tests in this class, all tests in this<br/>\n&gt; &gt; package, all tests labeled &quot;quick&quot;, etc.<br/>\n&gt; &gt;<br/>\n&gt; &gt; There are other ways of reducing test run time. For example, you could<br/>\n&gt; &gt; have<br/>\n&gt; &gt; a runner that runs 1 second worth of the tests that have failed most<br/>\n&gt; &gt; recently or a runner that runs half a second of recently failed tests plus<br/>\n&gt; &gt; half a second of randomly selected tests.<br/>\n&gt; &gt;<br/>\n&gt; &gt; In the end I think the systemic solution to test run times is to improve<br/>\n&gt; &gt; design and testing techniques to dramatically increase the assurance/CPU<br/>\n&gt; &gt; cycle ratio.<br/>\n&gt; &gt;<br/>\n&gt; &gt; I remember a friend&#39;s story of an early project that used tests<br/>\n&gt; &gt; extensively.<br/>\n&gt; &gt; After three years they had a carefully tuned suite that took ten minutes<br/>\n&gt; &gt; to<br/>\n&gt; &gt; run. When the test runtime increased beyond ten minutes, they would work<br/>\n&gt; &gt; on<br/>\n&gt; &gt; the design of the system and/or the design of the tests to improve the<br/>\n&gt; &gt; assurance/CPU cycle ratio and get the runtime back under ten minutes. Then<br/>\n&gt; &gt; most of the original team left.<br/>\n&gt; &gt;<br/>\n&gt; &gt; A few years later my friend was shown the system. The programmer proudly<br/>\n&gt; &gt; explained that the test suites now took 24 hours to run, even though the<br/>\n&gt; &gt; system had grown little in functionality. They had stopped paying<br/>\n&gt; &gt; attention<br/>\n&gt; &gt; to designing for testability. Every time they added a new axis of<br/>\n&gt; &gt; variability they blindly ran the cross product of the existing tests with<br/>\n&gt; &gt; all the alternatives for the new axis. Yes they had more tests, but A/C<br/>\n&gt; &gt; had<br/>\n&gt; &gt; dropped by several orders of magnitude.<br/>\n&gt; &gt;<br/>\n&gt; &gt; In short, I see using classification to reduce test runtime as a bandage<br/>\n&gt; &gt; masking the real problem which is low A/C. Using classification to reduce<br/>\n&gt; &gt; test runtime really is a hack and I hope people will continue working to<br/>\n&gt; &gt; improve design for testability. We will still provide some classification<br/>\n&gt; &gt; mechanism, but that doesn&#39;t make it not a hack.<br/>\n&gt; &gt;<br/>\n&gt; &gt; Assumptions<br/>\n&gt; &gt;<br/>\n&gt; &gt; The second reason I&#39;ve heard for classification is to avoid a slew of<br/>\n&gt; &gt; misleadingly failing tests. If my development machine doesn&#39;t have access<br/>\n&gt; &gt; to<br/>\n&gt; &gt; the database, then if I run the database tests I&#39;ll get a bunch of<br/>\n&gt; &gt; failures<br/>\n&gt; &gt; even though the system is really working (or, to be more precise, I don&#39;t<br/>\n&gt; &gt; have any information about whether the system is really working or not).<br/>\n&gt; &gt;<br/>\n&gt; &gt; Classification is one way to express assumptions. When I say &quot;@Test(groups<br/>\n&gt; &gt; =<br/>\n&gt; &gt; {&quot;database&quot;})&quot; I have declared something about this test. However, this<br/>\n&gt; &gt; expression seems limited and error-prone to me. I&#39;d prefer to have the<br/>\n&gt; &gt; power<br/>\n&gt; &gt; of a programming language to express my assumptions.<br/>\n&gt; &gt;<br/>\n&gt; &gt; In the JUnit 4.4 you can use assumeThat() to express assumptions. For<br/>\n&gt; &gt; example, you can say:<br/>\n&gt; &gt;<br/>\n&gt; &gt; public class DatabaseTest {<br/>\n&gt; &gt; @BeforeClass public static void isDatabaseAccessible() {<br/>\n&gt; &gt; User result= Database.login(&quot;kent&quot;);<br/>\n&gt; &gt; assumeThat(not(isError(result));<br/>\n&gt; &gt; }<br/>\n&gt; &gt; ...<br/>\n&gt; &gt; }<br/>\n&gt; &gt;<br/>\n&gt; &gt; This is a bit of a workaround because runner don&#39;t yet handle failed<br/>\n&gt; &gt; assumptions as anything other than successful tests, but it gives you a<br/>\n&gt; &gt; richer language to express assumptions than a textual classification<br/>\n&gt; &gt; scheme.<br/>\n&gt; &gt;<br/>\n&gt; &gt; The Point<br/>\n&gt; &gt;<br/>\n&gt; &gt; So now the point of this long post. Are there other uses of classification<br/>\n&gt; &gt; that I&#39;ve missed? Is the above way of expressing assumptions (or something<br/>\n&gt; &gt; derived from it like an explicit @Assumption) sufficient?<br/>\n&gt; &gt;<br/>\n&gt; &gt; Regards,<br/>\n&gt; &gt;<br/>\n&gt; &gt; Kent Beck<br/>\n&gt; &gt; Three Rivers Institute<br/>\n&gt; &gt;<br/>\n&gt; &gt; [Non-text portions of this message have been removed]<br/>\n&gt; &gt;<br/>\n&gt; &gt;<br/>\n&gt; &gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; [Non-text portions of this message have been removed]<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; Yahoo! Groups Links<br/>\n&gt;<br/>\n&gt;<br/>\n&gt;<br/>\n&gt; </span></blockquote></div>", 
    "prevInTime": 19732, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1186673944", 
    "canDelete": false, 
    "nextInTopic": 20376, 
    "prevInTopic": 19732, 
    "headers": {
        "inReplyToHeader": "PDE3ZmE1M2QwNzA4MDIwODU3eTQ2NWQ1YjAycmRjMmM5NjYwNmRhNjgxZjZAbWFpbC5nbWFpbC5jb20+", 
        "messageIdInHeader": "PDRmN2RhNmI5MDcwODA5MDgzOWg2ZTYyYWVmOHQ0N2EwYjdmNzJkYzQ0YzQzQG1haWwuZ21haWwuY29tPg==", 
        "referencesHeader": "PDAwMzEwMWM3Y2ZkNSRhZmY1ZTU2MCQ2NzAxYThjMEBrZW50c3BhdmlsaW9uPgkgPDE3ZmE1M2QwNzA4MDIwODU3eTQ2NWQ1YjAycmRjMmM5NjYwNmRhNjgxZjZAbWFpbC5nbWFpbC5jb20+"
    }
}