{
    "numMessagesInTopic": 13, 
    "nextInTime": 14966, 
    "senderId": "wFRPaiFst1oe4fnfQNCkcZFWyDWsCh5L_dEsMXq13N_tMhK5MSl3oKhC6l4lJ5bZdzUYTl6XnmAhvfEVYgk3gK29ThYizIIIm1o", 
    "systemMessage": false, 
    "subject": "Re: Will JUnit &#39;fail()&#39; trip up ALL code coverage tools?", 
    "from": "&quot;pmcb552000&quot; &lt;pmcb552000@...&gt;", 
    "authorName": "pmcb552000", 
    "msgSnippet": "Hi Elliotte, I completely agree - therefore, what would you recommend one should do about these code coverage warnings on JUnit fail() lines? I was thinking", 
    "msgId": 14965, 
    "profile": "pmcb552000", 
    "topicId": 14948, 
    "spamInfo": {
        "reason": "12", 
        "isSpam": false
    }, 
    "replyTo": "LIST", 
    "userId": 186505297, 
    "messageBody": "<div id=\"ygrps-yiv-1993902347\">Hi Elliotte,<br/>\n<br/>\nI completely agree - therefore, what would you recommend one should do<br/>\nabout these code coverage warnings on JUnit &#39;fail()&#39; lines?<br/>\n<br/>\nI was thinking of changing the &#39;fail()&#39; calls to &#39;assert(false)&#39;<br/>\ncalls, and then configuring Clover to ignore &#39;asserts()&#39;, but I&#39;m a<br/>\nlittle uncomfortable about that, as the semantics are not really the<br/>\nsame (ie. if I &#39;Run&#39; my tests as opposed to &#39;Debug&#39; them, then the<br/>\nasserts will be ignored by the Java runtime during the test run).<br/>\n<br/>\nMaybe I just have to live with these code coverage warnings until I<br/>\nupgrade to JUnit 4 (as David Saff describes, it has different usage,<br/>\nbut it will require JDK 5.0 - d&#39;oh!!).<br/>\n<br/>\nI still can&#39;t believe there is no simple answer here...?!<br/>\n<br/>\nPat.<br/>\n<br/>\n<br/>\n Rusty Harold &lt;elharo@m...&gt; wrote:<br/>\n<blockquote><span title=\"ireply\"> &gt; Ilja Preuss wrote:<br/>\n&gt; &gt; Why are you testing the coverage of your test code, not just your<br/>\n </span></blockquote>production<br/>\n<blockquote><span title=\"ireply\"> &gt; &gt; code?<br/>\n&gt; &gt; <br/>\n&gt; <br/>\n&gt; Same reason you test any other code: to make sure it&#39;s being run. When <br/>\n&gt; using code coverage tools on test code I&#39;ve found tests that weren&#39;t <br/>\n&gt; being executed due to incorrect naming conventions, asserts that<br/>\n </span></blockquote>weren&#39;t <br/>\n<blockquote><span title=\"ireply\"> &gt; reached due to bad logic, and vestigial code I no longer needed that <br/>\n&gt; could be deleted. There normally won&#39;t be as much untested code in the <br/>\n&gt; test suite as their is in the main body of code. However there&#39;s<br/>\n </span></blockquote>usually <br/>\n<blockquote><span title=\"ireply\"> &gt; some; and, while some of it are fail() statements and the like that you <br/>\n&gt; don&#39;t want to be reached, some of it is significant and requires a<br/>\n </span></blockquote>repair.<br/>\n<blockquote><span title=\"qreply\"> &gt; </span></blockquote></div>", 
    "prevInTime": 14964, 
    "specialLinks": [], 
    "contentTrasformed": false, 
    "postDate": "1127829528", 
    "canDelete": false, 
    "nextInTopic": 14966, 
    "prevInTopic": 14961, 
    "headers": {
        "inReplyToHeader": "PDQzMzkxQjgxLjMwMjAxMDZAbWV0YWxhYi51bmMuZWR1Pg==", 
        "messageIdInHeader": "PGRoYmo2bysxZjg0QGVHcm91cHMuY29tPg=="
    }
}